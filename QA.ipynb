{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Installs and imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: ijson in c:\\users\\kewi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.2.0.post0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\kewi\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: arabert in c:\\users\\kewi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: PyArabic in c:\\users\\kewi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from arabert) (0.6.15)\n",
      "Requirement already satisfied: farasapy in c:\\users\\kewi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from arabert) (0.0.14)\n",
      "Requirement already satisfied: emoji==1.4.2 in c:\\users\\kewi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from arabert) (1.4.2)\n",
      "Requirement already satisfied: requests in c:\\users\\kewi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from farasapy->arabert) (2.27.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kewi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from farasapy->arabert) (4.63.0)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\kewi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from PyArabic->arabert) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kewi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->farasapy->arabert) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kewi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->farasapy->arabert) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kewi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->farasapy->arabert) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\kewi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->farasapy->arabert) (2.0.12)\n",
      "Requirement already satisfied: colorama in c:\\users\\kewi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->farasapy->arabert) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\kewi\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install ijson\n",
    "%pip install arabert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import ijson\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read the data from** https://github.com/adelmeleka/AQAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "بيونسيه\n",
      "\n",
      "[{'qas': [{'question': 'متى بدأت بيونسي تصبح شعبية؟', 'id': 1, 'answers': [{'text': 'في أواخر التسعينات', 'answer_start': 220}], 'is_impossible': False}, {'question': 'ما هي المجالات التي تنافس عليها بيونسيه عندما كانت تكبر؟', 'id': 2, 'answers': [{'text': 'غناء ورقص', 'answer_start': 173}], 'is_impossible': False}, {'question': 'متى غادرت بيونسي طفل القدر وتصبح مغنية منفردة؟', 'id': 3, 'answers': [{'text': '(2003)،', 'answer_start': 515}], 'is_impossible': False}, {'question': 'في أي مدينة و ولاية نشأت بيونسيه؟', 'id': 4, 'answers': [{'text': 'هيوستن بولاية تكساس،', 'answer_start': 88}], 'is_impossible': False}, {'question': 'في أي عقد أصبحت بيونسي مشهورة؟', 'id': 5, 'answers': [{'text': 'أواخر التسعينات', 'answer_start': 223}], 'is_impossible': False}, {'question': 'في أي مجموعة R&B كانت هي المغنية الرئيسية؟', 'id': 6, 'answers': [{'text': 'دستنيز تشايلد', 'answer_start': 290}], 'is_impossible': False}, {'question': 'ما الألبوم الذي جعلها فنانة معروفة عالميا؟', 'id': 7, 'answers': [{'text': 'Dangerously in Love', 'answer_start': 476}], 'is_impossible': False}, {'question': 'من أدار مجموعة مصير الطفل؟', 'id': 8, 'answers': [{'text': 'ماثيو نولز،', 'answer_start': 332}], 'is_impossible': False}, {'question': 'متى صعدت بيونسي إلى الشهرة؟', 'id': 9, 'answers': [{'text': 'أواخر التسعينات', 'answer_start': 223}], 'is_impossible': False}, {'question': 'ما الدور الذي لعبه بيونسيه في طفل القدر؟', 'id': 10, 'answers': [{'text': 'فنان منفرد ناجح', 'answer_start': 545}], 'is_impossible': False}, {'question': 'ما هو أول ألبوم صدر بيونسيه كفنان منفرد؟', 'id': 11, 'answers': [{'text': 'Dangerously in Love', 'answer_start': 476}], 'is_impossible': False}, {'question': 'متى أطلقت بيونسيه خطير في الحب؟', 'id': 12, 'answers': [{'text': '(2003)،', 'answer_start': 515}], 'is_impossible': False}, {'question': 'كم عدد جوائز Grammy التي فازت بها Beyoncé لأول ألبوم منفرد لها؟', 'id': 13, 'answers': [{'text': 'خمسة', 'answer_start': 604}], 'is_impossible': False}, {'question': 'ماذا كان دور بيونسيه في طفل القدر؟', 'id': 14, 'answers': [{'text': 'فنان منفرد ناجح', 'answer_start': 545}], 'is_impossible': False}, {'question': 'ما هو اسم أول ألبوم منفرد لبيونسي؟', 'id': 15, 'answers': [{'text': 'Dangerously in Love', 'answer_start': 476}], 'is_impossible': False}], 'context': 'بيونسي جيزيل نولز-كارتر (من مواليد 4 سبتمبر، 1981)، المعروفة باسم بيونسي. ولدت ونشأت في هيوستن بولاية تكساس، هي مغنية وممثلة أميركية حائزة على 23 جائزة غرامي.غنت في مسابقات غناء ورقص مختلفة عندما كانت طفلة، أصبحت مشهورة في أواخر التسعينات كمغنية آر أند بي (رئيسية) للفرقة الغنائية النسائية دستنيز تشايلد. والتي أديرت من قِبل والدها ماثيو نولز، وأصبحت الفرقة واحدة من الأكثر مبيعاً في العالم من الفرق النسائية على الإطلاق. وقد شهد إنفصال الفرقة المؤقت صدور ألبوم بيونسي الأول  Dangerously in Love دانجيروسلي إن لوف  (2003)، والذي أنشأها بأن تكون فنان منفرد ناجح في العالم؛ بيعت منه 16 مليون نسخة، حصل على خمسة جوائز غرامي وتضمن الأغاني التي وصلت إلى قمة الرسم البياني الأمريكي بيلبورد هوت 100 \"كريزي إن لوف\" و\"بيبي بوي\". \\n'}, {'qas': [{'question': 'في أي مدينة ذهبت بيونسي إلى المدرسة؟', 'id': 16, 'answers': [{'text': 'فريدريكسبورغ', 'answer_start': 63}], 'is_impossible': False}, {'question': 'من كان أول شخص يلاحظ قدرة بيونسي على الغناء؟', 'id': 17, 'answers': [{'text': 'دارلاتا جونسون', 'answer_start': 128}], 'is_impossible': False}, {'question': 'انتقلت بيونسي إلى أي مدينة بعد أن تركت مدرستها الابتدائية الأولى؟', 'id': 18, 'answers': [{'text': 'هيوستن،', 'answer_start': 849}], 'is_impossible': False}, {'question': 'أي من أساتذتها اكتشفوا موهبة بيونسي الموسيقية؟', 'id': 19, 'answers': [{'text': 'جونسون مدرس الرقص لبيونسي', 'answer_start': 136}], 'is_impossible': False}, {'question': 'أنا الكنيسة التي كانت بيونسيه عضو وعازف منفرد في الجوقة؟', 'id': 20, 'answers': [{'text': 'القديس', 'answer_start': 43}], 'is_impossible': False}, {'question': 'ما نوع المدرسة التي كانت مدرسة باركر الابتدائية؟', 'id': 21, 'answers': [{'text': 'مدرسة أليف السيك،', 'answer_start': 882}], 'is_impossible': False}, {'question': 'ما الأغنية التي غنتها بيونسي للفوز في مسابقة في سن السابعة؟', 'id': 22, 'answers': [{'text': 'من', 'answer_start': 334}], 'is_impossible': False}, {'question': 'في أي مدينة تقع مدرسة بيونسي الابتدائية؟', 'id': 23, 'answers': [{'text': 'فريدريكسبورغ', 'answer_start': 63}], 'is_impossible': False}, {'question': 'ما اسم أول مدرب للرقص في بيونسيه؟', 'id': 24, 'answers': [{'text': 'دارلاتا جونسون', 'answer_start': 128}], 'is_impossible': False}, {'question': 'ما الجوقة التي غنتها بيونسي لمدة عامين؟', 'id': 25, 'answers': [{'text': 'القديس', 'answer_start': 43}], 'is_impossible': False}], 'context': \"حصلت بيونسي على تعليمها الإبتدائي في مدرسة القديس ماري التي في فريدريكسبورغ (تكساس). وحصلت هناك أيضاً على دروس الرقص. وقد اكتشف دارلاتا جونسون مدرس الرقص لبيونسي موهبتها الغنائية عندما بدأت في همهمة تلحين أغنية بصوتها (إحدى الأغنيات)، وقد ضغط عليها حتى تكمل الأغنية. وقد فازت بيونسي في مسابقة للغناء وأداء الصوت عندما كانت في السابعة من عمرها، وباقي المشتركين في الخامسة عشر، والسادسة عشر. وقد قامت بغناء أغنية تخيل للمغن والشاعر وعازف جيتار فرقة البيتلز جون لينون. وهي أغنية تصف عالمًا مثاليًا تتحقق فيه المساواة والسلام بين بني البشر. الأغنية من كلمات جون لينون ومن إخراج فيل سبيكتور. وقد صدرت لأول مرة عام-1971 كجزء من ألبوم إيماجين. وتعد الأغنية واحدة من أفضل الأغاني وأكثرها شيوعًا، وفي عام 2004 حلت في المرتبة الثالثة على قائمة رولينغ ستون لأفضل خمسمائة أغنية في التاريخ. وفي خريف عام 1990، وتنضم بيونسي إلى مدرسة باركر الابتدائية للموسيقى في هيوستن، تكساس. وبعد ذلك ذهبت إلى مدرسة أليف السيك، الثانوية للفنون المسرحية والفنون البصرية. بالإضافة إلى قضائها سنتين كاملتين في مدرسة الكنيسة الميثودية المتحدة St. John's.\\n\"}, {'qas': [{'question': 'من قرر وضع مجموعة بيونسيه في برنامج Star Search في عرض المواهب؟', 'id': 26, 'answers': [{'text': 'آرنى فراجير', 'answer_start': 299}], 'is_impossible': False}, {'question': 'من كان أول علامة سجل لإعطاء الفتيات صفقة قياسية؟', 'id': 27, 'answers': [{'text': 'مع إلكترا', 'answer_start': 829}], 'is_impossible': False}, {'question': 'من الذي أحضر بيونسي إلى كاليفورنيا ودخل مجموعتها في Star Search؟', 'id': 28, 'answers': [{'text': 'آرنى فراجير', 'answer_start': 299}], 'is_impossible': False}, {'question': 'في أي عام ترك والد بيونسي وظيفته لإدارة مجموعتها؟', 'id': 29, 'answers': [{'text': '1995', 'answer_start': 527}], 'is_impossible': False}, {'question': 'ما هي شركة التسجيلات الكبيرة التي سجلت أول ألبوم لمجموعة بيونسيه؟', 'id': 30, 'answers': [{'text': 'سوني للموسيقى', 'answer_start': 1173}], 'is_impossible': False}, {'question': 'ما شركة تسجيل وقعت لأول مرة مجموعة بيونسي وقطعت في وقت لاحق لهم؟', 'id': 31, 'answers': [{'text': 'مع إلكترا', 'answer_start': 829}], 'is_impossible': False}, {'question': 'من وضع Tyme الفتاة في البحث عن النجوم؟', 'id': 32, 'answers': [{'text': 'آرنى فراجير', 'answer_start': 299}], 'is_impossible': False}, {'question': 'من وقع على مجموعة الفتاة في 5 أكتوبر 1995؟', 'id': 33, 'answers': [{'text': 'للتسجيلات في', 'answer_start': 839}], 'is_impossible': False}], 'context': 'وتقابلت بيونسي وصديقة طفولتها كيلي رولاند مع لا تفيا روبرسون في انتخابات مجموعات التسلية والترفيه التي تكونت من تجمع فتيات في عمر الثمانية. وقاموا بإنشاء مجموعة مع ثلاث فتيات آخريات وأسسوها بعنوان فتاة التيمي وقاموا بالرقص وغناء الراب في نطاق مسابقة المواهب في هيوستن. وبعد الإطلاع على المجموعة قام آرنى فراجير منتج R&B بإحضار الفتيات إلى الإستوديو في شمال كاليفورنيا، وفي ذلك الوقت شاركوا في مسابقة (البحث عن نجم) أكبر مسابقة مواهب عُرضت على شاشة التلفاز. وقامت بيونسي بأداء أغنية في مسابقة فتاة التيمي ولكنها لم تفز. وفي عام 1995 غادر والد بيونسي إدارة المجموعة. ونتيجة لذلك فقد حدّ دخل عائلة بيونسي واضطر كل من والدها ووالدتها الانتقال إلى شقق منفصلة. وانخفض مستوى مجموعة ماثيو المبتكر إلى الترتيب الرابع واستمرت هذه المجموعة في الظهور على المسرح وحتى من قبل ظهور مجموعة الفتيات R&B المعروفين. وقامت هذه المجموعة بعقد إتفاقية مع إلكترا للتسجيلات في عام 1995 وبعد وقت لاحق من هذه الإتفاقية تم إنهاؤها من قبل الشركة، وأدى هذا الحدث إلى زيادة التوتر في العائلة وانفصل والديّ بيونسي. وفي الخامس من شهر أكتوبر عام 1995 قامت الشعبية الترفيهية صاحبة دويني ويغينز بعقد إتفاقية مع الفتيات. وفي عام 1996 بدأت المجموعة بتسجيل ألبومها الأول في إطار الإتفاقية والذي قام بإنتاجه شركة سوني للموسيقى. وتوحدت أسرة نولز من جديد وبعد فترة ما وقعت الفتيات إتفاقية جديدة مع كولومبيا للتسجيلات.\\n'}, {'qas': [{'question': '\"الملائكة تشارلي\" ظهرت أي واحد من أعضاء الفرقة؟', 'id': 34, 'answers': [{'text': 'بيعت منه أكثر', 'answer_start': 1007}], 'is_impossible': False}, {'question': 'باع ألبومهم الثالث ، Survivor ، كم خلال أسبوعه الأول؟', 'id': 35, 'answers': [{'text': 'نسخة', 'answer_start': 1032}], 'is_impossible': False}, {'question': 'ما هو الملحن الفرنسي الذي كتب الأوبرا الأصلية \"كارمن\" في القرن التاسع عشر؟', 'id': 36, 'answers': [{'text': 'جيمس', 'answer_start': 367}], 'is_impossible': False}, {'question': 'النساء المستقلات الجزء الأول كان على 2000 فيلم موسيقى؟', 'id': 37, 'answers': [{'text': 'ساشا فيرس', 'answer_start': 438}], 'is_impossible': False}, {'question': 'ما الفيلم الذي نجحت بيونسي في إنتاجه عام 2001 مع Mekhi Phifer؟', 'id': 38, 'answers': [{'text': 'من قِبل', 'answer_start': 976}], 'is_impossible': False}, {'question': 'متى أعلن مصير الطفل عن توقفه؟', 'id': 39, 'answers': [{'text': 'فيرس (2008)،', 'answer_start': 443}], 'is_impossible': False}], 'context': 'بعد انفصال دستنيز تشايلد في 2005، أصدرت ألبومها الإستديو الثاني المنفرد بي دي (2006)، والذي تضمن الأغاني التي نجحت عالمياً \"أيربليسبل\" و\"بيوتفل لاير\". بيونسي معروفة في التمثيل أيضاً، مع أدائها الذي ترشح لجائزة جولدن جلوب في دريم قيرلز (2006). وأدوار بطولة أخرى في ذا بينك بانتر (2006) وأوبسيسد (2009). وتزوجت من مغني الراب جي-زي وتجسيدها للشخصية المغنية الراحلة إيتا جيمس في كاديلاك ريكوردز (2008) أثر على ألبومها الإستديو الثالث، آيم... ساشا فيرس (2008)، والذي شهد ولادة الشخصية البديلة ساشا فيرس وحصل الألبوم على ستة جوائز غرامي في 2010، بما في ذلك أغنية السنة لأغنية \"سنقل ليديز (بوت آ رينق أون إت)\". أخذت بيونسي إجازة من عالم الفن في عام 2010 وتولت إدارة حياتها المهنية، أصدرت ألبومها الإستديو الرابع 4 (2011) الذي كان يحتوي على نبرة ناضجة أكثر من ألبوماتها السابقة، واستكشفت موسيقى الفانك الذي كان في السبعينات مع هذا الألبوم، والبوب في الثمنينات والسول التسعينات، كما أن ألبوم \\'4\\' تسرب بشكل كامل قبل صدوره بشكل رسمي مما يجعل الألبوم أكثر ألبوم تم تحميله بشكل غير قانوني من قِبل فنانة أنثى، رغم تسريبه بيعت منه أكثر من 8 مليون نسخة عالمياً  ألبومها الإستديو الخامس، بيونسي (2013)، تلقى الألبوم على الكثير من المراجعات الإيجابية من نقاد الموسيقى وفضلوه على ألبوماتها السابقة بسبب نوع الألبوم المظلم، كما أن الألبوم تم صدوره بشكل مفاجئ وبيعت منه 828,773 نسخة عالمياً في أول ثلاث أيام من صدوره من دون أي ترويج مسبق.\\n'}, {'qas': [{'question': 'كم عدد نسخ ألبوماتها التي باعتها بيونسي في الولايات المتحدة؟', 'id': 40, 'answers': [{'text': 'مليون', 'answer_start': 221}], 'is_impossible': False}, {'question': 'إجمالي في جميع أنحاء العالم ، كم عدد السجلات التي بيعت بيونسيها؟', 'id': 41, 'answers': [{'text': 'مليون', 'answer_start': 221}], 'is_impossible': False}, {'question': 'عندما كانت بيونسيه مع Destiny Child ، كم عدد الألبومات التي تمكنت من بيعها؟', 'id': 42, 'answers': [{'text': 'و60 مليون', 'answer_start': 275}], 'is_impossible': False}, {'question': 'من كانت أول امرأة تحصل على جائزة الفنان العالمي في جوائز الموسيقى الأمريكية؟', 'id': 43, 'answers': [{'text': 'بيونسي', 'answer_start': 400}], 'is_impossible': False}, {'question': 'كم عدد الألبومات التي بيعت بيونسي كفنان منفرد في الولايات المتحدة؟', 'id': 44, 'answers': [{'text': 'مليون', 'answer_start': 221}], 'is_impossible': False}, {'question': 'كم باعت في جميع أنحاء العالم؟', 'id': 45, 'answers': [{'text': 'مليون', 'answer_start': 221}], 'is_impossible': False}, {'question': \"كم عدد السجلات التي باعتها مع Destiny's Child؟\", 'id': 46, 'answers': [{'text': 'و60 مليون', 'answer_start': 275}], 'is_impossible': False}, {'question': 'متى حصلت على جائزة الأسطورة؟', 'id': 47, 'answers': [{'text': 'جوائز موسيقى', 'answer_start': 103}], 'is_impossible': False}, {'question': 'كم عدد السجلات التي باعتها بيونسيه في الولايات المتحدة؟', 'id': 48, 'answers': [{'text': 'أكثر من 200 مليون', 'answer_start': 209}], 'is_impossible': False}, {'question': 'كم عدد السجلات التي باعها بيونسيه في جميع أنحاء العالم؟', 'id': 49, 'answers': [{'text': 'أكثر من 200 مليون', 'answer_start': 209}], 'is_impossible': False}, {'question': 'متى حصلت بيونسيه على جائزة الأسطورة؟', 'id': 50, 'answers': [{'text': 'جوائز موسيقى', 'answer_start': 103}], 'is_impossible': False}], 'context': 'وحصلت على 23 جائزة غرامي وهي المرأة الأكثر ترشيحًا في تاريخ الجائزة، وهي أيضًا الفنانة الأكثر حصدًا في جوائز موسيقى فيديو MTV ، مع 24 فوزًا ،  وأكثر من 600 جائزة طوال حياتها المهنية التي امتدت 16 عاماً، وباعت أكثر من 200 مليون نسخة من الألبومات والأغاني المنفردة كفنان منفرد و60 مليون مع دستنيز تشايلد، مما يجعلها واحدة من أفضل الفنانين مبيعاً على الإطلاق. أعترفت جمعية صناعة التسجيلات الأمريكية بأن بيونسي أعلى فنان معتمد في أمريكا خلال العقد 2000s. في 2009، سميت بيلبورد بيونسي أعلى فنان راديو لهذا العقد، أعلى فنانة من عقد 2000s وفنان الألفية من قبل بيلبورد في عام 2011. في 2014، أدرجت تايم بيونسي واحدة من أكثر 100 شخصية مؤثرة في العالم.\\n'}]\n"
     ]
    }
   ],
   "source": [
    "with open('AQAD-master/AQQAD 1.0/FINAL_AAQAD-v1.0.json','rb') as f:\n",
    "  data = json.load(f)\n",
    "\n",
    "for allData in data['data']:\n",
    "    print(allData['title']+\"\\n\")\n",
    "    print(allData['paragraphs'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        squad_dict = json.load(f)\n",
    "\n",
    "    # initialize lists for contexts, questions, and answers\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    # iterate through all data in squad data\n",
    "    for group in squad_dict['data']:\n",
    "        for passage in group['paragraphs']:\n",
    "            context = passage['context']\n",
    "            for qa in passage['qas']:\n",
    "                question = qa['question']\n",
    "                if 'plausible_answers' in qa.keys():\n",
    "                    access = 'plausible_answers'\n",
    "                else:\n",
    "                    access = 'answers'\n",
    "                for answer in qa['answers']:\n",
    "                    # append data to lists\n",
    "                    contexts.append(context)\n",
    "                    questions.append(question)\n",
    "                    answers.append(answer)\n",
    "    # return formatted data lists\n",
    "    return contexts, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts, questions, answers = parse_data('AQAD-master/AQQAD 1.0/FINAL_AAQAD-v1.0.json')\n",
    "#splitting the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_contexts, val_contexts, train_questions, val_questions, train_answers, val_answers = train_test_split(contexts, questions, answers, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ما الذي تم بناء استاد فرنسا من أجله؟',\n",
       " 'كيف ألقاب الجماعة درع لديه أرسنال؟',\n",
       " 'في أي اتجاه يُنشر الخشب في كثير من الأحيان بحيث تظهر عقدة كدائرة صلبة تتدفق الحبوب حولها؟']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': 'كأس العالم لكرة القدم', 'answer_start': 187},\n",
       " {'text': '2014،', 'answer_start': 919},\n",
       " {'text': 'الألواح بطول 366 سم وبعرض', 'answer_start': 9}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['يوجد في باريس العديد من الملاعب المخصصة لمختلف أنواع الرياضات. يعدّ ملعب فرنسا الذي يتسع لأكثر من 80 ألف متفرج أكبر ملاعب البلاد، وكان قد بني هذا الملعب الواقع في منطقة سان دينس لاستضافة كأس العالم لكرة القدم 1998 والذي حازت عليه فرنسا للمرة الأولى في تاريخها. يستخدم الملعب لممارسة كرة القدم، والرجبي، وألعاب القوى. يستضيف الملعب مباريات منتخب فرنسا الوطني للرجبي سنوياً في بطولة الأمم الستة. وكذلك يستضيف مباريات منتخب فرنسا لكرة القدم الودية وتصفيات البطولات الكبرى. بالإضافة إلى نادي باريس سان جيرمان، تملك المدينة نوادي كرة قدم أخرى مثل: نادي باريس، والنجم الأحمر ونادي فرنسا.\\n',\n",
       " 'شهد عام 2006 نجاحا للأرسنال على المستوى الأوروبي حيث تأهل للمرة الأولى في تاريخيه إلى المباراة النهائية لدوري أبطال أوروبا التي أقيمت في العاصمة الفرنسية باريس وجمعت الأرسنال مع نادي برشلونة الإسباني وكان الأرسنال قريبا من تحقيق لقبه الأوروبي الأول بعد أن أنهى الشوط الأول بتقدمه بهدف سجله مدافعه الإنجليزي سول كامبل. لكن أحلامهم في الحصول على اللقب تبددت بعد أن تمكن النادي الإسباني من قلب النتيجة لصالحه بتسجيله هدفين في الربع الأخير من المباراة ليتوج بذلك بطل لأوروبا على حساب الآرسنال. وفي يوليو 2006، انتقل النادي إلى ملعبه الجديد ملعب الإمارات بعد 93 سنة في قضاها في معلب الهايبري. وصل أرسنال إلى نهائي كأس الرابطة الإنجليزية للمحترفين في موسم 2010–11، وخسر بنتيجة 2-1 لصالح برمنغهام سيتي، وأصبح منذ بداية شهر مارس من عام 2011، أحد الأندية الأربعة (الثلاثة الأخرى هي: مانشستر يونايتد، بلاكبيرن روفرز، وتشيلسي) التي فازت بكأس بطولة الدوري الإنجليزي، منذ تأسيسها عام 1992. لم يظفر أرسنال بأي بطولة مهمة حتى 17 مايو 2014، عندما هزم نادي هال سيتي في نهائي كأس الاتحاد الإنجليزي لكرة القدم بنتيجة 3–2 بعد أن كان متراجعاً في بداية المباراة بنتيجة 2–0، فتأهل نتيجة لذلك إلى بطولة درع الاتحاد الإنجليزي لسنة 2014، حيث نافس بطل الدوري الممتاز مانشستر سيتي، وفاز عليه بنتيجة 3–0 ليحرز بطولة ثانية خلال ثلاثة أشهر فقط. وبعد حوالي تسعة شهور من الفوز بدرع الاتحاد الإنجليزي، عاود أرسنال الظهور في بطولة كأس الاتحاد الإنجليزي للسنة الثانية على التوالي، ليهوم نادي أستون فيلا في النهائي بنتيجة 4–0 ويُصبح بالتالي أنجح النوادي في تاريخ هذه اليطولة، بعد أن ظفر بها 12 مرة خلال تاريخه. وبتاريخ 2 أغسطس 2015 هزم أرسنال نادي تشيلسي بنتيجة 1–0 في ملعب ومبرلي ليحتفظ بلقبه كبطل درع الاتحاد، للمرة الرابعة عشر.\\n',\n",
       " 'تنتج هذه الألواح بطول 366 سم وبعرض 122 سم عادة وإن كانت بعض المصانع الأجنبية تنتج ألواحاً بطول 500 سم أيضاً. ويختلف الخشب المضغوط عن الخشب الحبيبي في أن صناعة الأول تتم بعد تحويل الألياف السليلوزية إلى عجينة شبيهة بعجينة الورق ثم تخلط بالراتنج (الصمغ)، ويتم تشكيل الألواح بالضغط العالي عند درجات حرارة مرتفعة كما هو الحال في الخشب الحبيبي، إلا أن الألواح الخشبية تعالج بعد ذلك في أفران للتحميص حتى لا تتأثر مستقبلاً بتغييرات درجات الحرارة أو الرطوبة الموجودة في الجو.\\n']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "1150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ما هي البكتيريا التي تسبب عدوى السل؟',\n",
       " 'ما هي البكتيريا التي تسبب مرض الحمى التي رصدت في جبال روكي؟',\n",
       " 'كم من السكان الأصليين بالقرب من ولاية ماساتشوستس لقوا حتفهم بسبب الجدري في الوباء بين عامي 1617 و 1619؟']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': 'السل', 'answer_start': 89},\n",
       " {'text': 'أنواع', 'answer_start': 706},\n",
       " {'text': '30% من الأمريكيين الأصليين القاطنين في', 'answer_start': 512}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['من المُقدّر أن حوالي 5 - 10٪ من غير المُصابين بفيروس نقص المناعة البشرية والمصابين بعدوى السل سيصبح مرضهم نشطًا خلال حياتهم وفي المقابل، فإن 30٪ من المُصابين بفيروس نقص المناعة البشرية سيصبح مرضهم نشطًا. قد يُصيب السل أي جزء من الجسم، ولكن إصابته للرئتين تُعتبر الأكثر شيوعًا (وهو ما يُعرف باسم السل الرئوي). يحدث السل خارج الرئوي عندما يتطور مرض السل خارج الرئتين. قد يتشارك السل خارج الرئوي مع السل الرئوي أيضًا  تشمل العلامات والأعراض العامة الحمى والقشعريرة والتعرق الليلي وفقدان الشهية وفقدان الوزن والتعب،  وقد يحدث تعجّر الأصابع الواضح أيضًا.\\n',\n",
       " 'يمتلك كل نوع من الأمراض مميزات خاصة به تمكنه من التفاعل مع مستقبلاته في الجسم البشري. فبعض الكائنات الحية مثل المكورات العقدية يمكن أن تسبب الالتهابات الجلدية، والالتهاب الرئوي، والسحايا، وتسمم الدم حيث ينتج صدمة فتتوسع وتتضخم الأوعية مما يسبب الموت. مع ذلك فإن هذه الكائنات الحية هي أيضا جزء من الإنسان، وعادةً ما تتواجد على الجلد أو في الأنف من دون أن تسبب أي مرض على الإطلاق. وهناك كائنات أخرى دائماً تسبب الأمراض لدى البشر مثل الريكتسية وهي من الطفيليات، حيث تتواجد وتنمو وتتكاثر داخل خلايا الكائنات الحية الأخرى. كما أن هناك نوع واحد من الريكتسية يسبب التيفوس، في حين يسبب البعض حمى جبال روكي المبقعة. بالإضافة إلى أن هناك شعبة الكلاميديا وهي من الطفيليات التي تنمو وتتكاثر داخل الخلايا حيث تحتوي على أنواع من الممكن أن تسبب الالتهاب الرئوي، والتهاب المسالك ويمكن أن تشارك في أمراض القلب التاجية.] وأخيرا، بعض الأنواع مثل الزائفة الزنجارية وبيركولديري، والمتفطرة الطيرية من مسببات الأمراض الانتهازية وتسبب المرض بشكل خاص لدى الأشخاص الذين يعانون من ضعف المناعة والتليف الكيسي.\\n',\n",
       " 'يقدر أن الاجتياح المتكرر بالإنفلونزا والحصبة والجدري أدى في تناقص ما قدر بنصف إلى ثلثي السكان الأصليين لشرق أمريكا الشمالية في ظرف قرن من الغزو الأوروبي للمنطقة، وقد قدر أن الجدري تسبب في فناء 90% من السكان الأصليين لمستعمرة خليج ماساتشوستس، كما تسبب انتقال فيروس الجدري من الأوروبيين إلى الأمريكيين الأصليين في بلايموث (بولاية ماساتشوستس الحالية) في انقراضهم جميعاً. وقد وصل المرض إلى منطقة بحيرة أونتاريو سنة 1836 وإلى أراضي الإيروكواس بحلول عام 1679. وفي سبعينيات القرن الثامن عشر قضى الجدري على ما لا يقل عن 30% من الأمريكيين الأصليين القاطنين في الساحل الغربي للولايات المتحدة، كما تسببت أوبئة الجدري التي حلت في الفترة بين عامي 1780 و1782 وفي الفترة بين عامي 1837 و1838 في تناقص شديد في أعداد هنود منطقة السهول. وكانت حكومة الولايات المتحدة الأمريكية قد نظمت برنامجاً لتطعيم الأمريكيين الأصليين ضد الجدري سنة 1832 (قانون تطعيم الهنود لسنة 1832).\\n']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(train_questions))\n",
    "display(train_questions[0:3])\n",
    "print(len(train_answers))\n",
    "display(train_answers[0:3])\n",
    "print(len(train_contexts))\n",
    "display(train_contexts[0:3])\n",
    "print('-----------------------------------------')\n",
    "print(len(val_questions))\n",
    "display(val_questions[0:3])\n",
    "print(len(val_answers))\n",
    "display(val_answers[0:3])\n",
    "print(len(val_contexts))\n",
    "display(val_contexts[0:3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Arabert processor from** https://github.com/aub-mind/arabert"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing the dataset using arabert in addition to this SQuAD preprocessing guide** https://www.youtube.com/watch?v=ZIRmXkHp0-c&t=287s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_end_idx(answers, contexts):\n",
    "    # loop through each answer-context pair\n",
    "    for answer, context in zip(answers, contexts):\n",
    "        # gold_text refers to the answer we are expecting to find in context\n",
    "        gold_text = answer['text']\n",
    "        # we already know the start index\n",
    "        start_idx = answer['answer_start']\n",
    "        # and ideally this would be the end index...\n",
    "        end_idx = start_idx + len(gold_text)\n",
    "\n",
    "        # ...however, sometimes squad answers are off by a character or two\n",
    "        if context[start_idx:end_idx] == gold_text:\n",
    "            # if the answer is not off :)\n",
    "            answer['answer_end'] = end_idx\n",
    "        else:\n",
    "            for n in [1, 2]:\n",
    "                if context[start_idx-n:end_idx-n] == gold_text:\n",
    "                    # this means the answer is off by 'n' tokens\n",
    "                    answer['answer_start'] = start_idx - n\n",
    "                    answer['answer_end'] = end_idx - n\n",
    "add_end_idx(train_answers, train_contexts)\n",
    "add_end_idx(val_answers, val_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'answers without answer_end key:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'non matching answers:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'answers without answer_end key:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'non matching answers:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loop over train answers and train contexts and make sure that they match\n",
    "def check_answers_contexts_match(answers, contexts, questions, show_anamolies=False):\n",
    "    \n",
    "    answers_without_answer_end_key =0\n",
    "    non_matching_answers=0\n",
    "    for answer, context, question in zip(answers, contexts, questions):\n",
    "        \n",
    "        #check if context has key answer_end and if not \n",
    "        if 'answer_end' not in answer.keys():\n",
    "            answers_without_answer_end_key +=1\n",
    "            if show_anamolies:\n",
    "                print(question)\n",
    "                print(answer)\n",
    "                print(context[answer['answer_start']:answer['answer_start']+ len(answer['text'])+1])\n",
    "            continue \n",
    "\n",
    "        #check if answer matches context\n",
    "        if context[answer['answer_start']:answer['answer_end']] != answer['text']:\n",
    "            non_matching_answers +=1\n",
    "    display('answers without answer_end key:', answers_without_answer_end_key,'non matching answers:', non_matching_answers)\n",
    "    \n",
    "check_answers_contexts_match(train_answers, train_contexts, train_questions)\n",
    "check_answers_contexts_match(val_answers, val_contexts, val_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "arabert_tokenizer = AutoTokenizer.from_pretrained(\"aubmindlab/bert-base-arabert\",\n",
    "                                                    do_lower_case=False,\n",
    "                                                    do_basic_tokenize=True,\n",
    "                                                    remove_html_markup = False,\n",
    "                                                    strip_tashkeel = True,\n",
    "                                                    strip_tatweel = True,\n",
    "                                                    keep_emojis = True,\n",
    "                                                    insert_white_spaces = True,\n",
    "                                                    replace_slash_with_dash = True,\n",
    "                                                    apply_farasa_segmentation = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of encoding: 93\n",
      " number of words around splitted spaces : 41\n",
      "number of tokens that are not in the vocab: 0\n",
      "استضافت المطربة المصرية أم كلثوم احتفال الجمهور بعودة الضباط رغم تحفظات الحكومة الملكية، التي كانت قد تعرضت لضغوط من قبل الحكومة البريطانية لمنع الاستقبال، وزاد ذلك من عزم عبد الناصر على الإطاحة بالملكية. بدأ عبد الناصر كتابة \"فلسفة الثورة\" أثناء الحصار.\n",
      "\n",
      "['استضاف', '##ت', 'ال', '##مطر', '##ب', '##ة', 'ال', '##مصري', '##ة', 'أم', 'كلثوم', 'احتفال', 'ال', '##جمهور', 'ب', '##عود', '##ة', 'ال', '##ضب', '##اط', 'رغم', 'تحفظ', '##ات', 'ال', '##حكوم', '##ة', 'ال', '##ملكي', '##ة', '،', 'التي', 'كان', '##ت', 'قد', 'تعرض', '##ت', 'ل', '##ض', '##غوط', 'من', 'قبل', 'ال', '##حكوم', '##ة', 'ال', '##بريطاني', '##ة', 'لم', '##ن', '##ع', 'ال', '##اس', '##ت', '##قب', '##ال', '،', 'و', '##زاد', 'ذلك', 'من', 'عزم', 'عبد', 'ال', '##ناصر', 'على', 'ال', '##إ', '##طاح', '##ة', 'بالم', '##لك', '##ي', '##ة', '.', 'بدأ', 'عبد', 'ال', '##ناصر', 'كتاب', '##ة', '\"', 'فلسف', '##ة', 'ال', '##ثور', '##ة', '\"', 'أثناء', 'ال', '##حصار', '.']\n",
      "length of encoding: 224\n",
      " number of words around splitted spaces : 114\n",
      "number of tokens that are not in the vocab: 5\n",
      "كان عام 1970 عام مميز لأرسنال حيث تمكن بعد تغلبه بنتيجة 4-3 على نادي آندرلخت من الفوز بأول بطولة أوروبية غير رسمية في تاريخه وهي بطولة كأس المعارض (بالإنجليزية: Inter-Cities Fairs Cup) والتي دمجت مع كأس الاتحاد الأوروبي فيما بعد. وقد تبع هذا الفوز فوز كبير آخر، هو الفوز بكأس بطولتيّ الدوري والاتحاد في ذات الوقت، في موسم 1970–71. لازم الحظ السيئ أرسنال في الأعوام 1978، 1979 و1980 حيث أنه تأهل لنهائي الكأس الإنجليزي ثلاث مرات على التوالي لكنه خسرها كلها. حقق الفريق نجاحًا وحيدًا فقط خلال هذه الفترة، كان فوزه في الدقيقة الأخيرة على نادي مانشستر يونايتد بنتيجة 3–2، في نهائي كأس الاتحاد الإنجليزي لعام 1979، بمباراة كثيرًا ما يعدّها المعجبون مباراة كلاسيكية.\n",
      "\n",
      "['كان', 'عام', '1970', 'عام', 'مميز', 'لأ', '##رسن', '##ال', 'حيث', 'تمكن', 'بعد', 'تغلب', '##ه', 'بنت', '##يج', '##ة', '4', '-', '3', 'على', 'نادي', 'آند', '##ر', '##ل', '##خت', 'من', 'ال', '##فوز', 'ب', '##أول', 'بطول', '##ة', 'أوروبي', '##ة', 'غير', 'رسمي', '##ة', 'في', 'تاريخ', '##ه', 'و', '##ه', '##ي', 'بطول', '##ة', 'كأس', 'ال', '##معارض', '(', 'ب', '##ال', '##إن', '##جلي', '##زي', '##ة', ':', 'I', '##nter', '-', 'Citi', '##es', 'F', '##airs', 'Cu', '##p', ')', 'و', '##التي', 'دمج', '##ت', 'مع', 'كأس', 'ال', '##ات', '##حاد', 'ال', '##أوروبي', 'فيما', 'بعد', '.', 'و', '##قد', 'تبع', 'هذا', 'ال', '##فوز', 'فوز', 'كبير', 'آخر', '،', 'هو', 'ال', '##فوز', 'بك', '##أس', '[UNK]', 'ال', '##دوري', 'والا', '##ت', '##حاد', 'في', 'ذات', 'ال', '##وق', '##ت', '،', 'في', 'موسم', '1970', '–', '71', '.', 'لازم', 'ال', '##حظ', 'ال', '##سيئ', 'أرسنال', 'في', 'ال', '##أع', '##وا', '##م', '1978', '،', '1979', 'و', '##198', '##0', 'حيث', 'أن', '##ه', 'تأهل', 'لن', '##ها', '##ئي', 'ال', '##ك', '##أس', 'ال', '##إن', '##جلي', '##زي', 'ثلاث', 'مر', '##ات', 'على', 'ال', '##ت', '##وا', '##لي', 'لكن', '##ه', 'خسر', '##ها', 'كل', '##ها', '.', 'حقق', 'ال', '##فريق', '[UNK]', '[UNK]', 'فقط', 'خلال', 'هذه', 'ال', '##فتر', '##ة', '،', 'كان', 'فوز', '##ه', 'في', 'ال', '##دق', '##يق', '##ة', 'ال', '##أخير', '##ة', 'على', 'نادي', 'مانشستر', 'يونايتد', 'بنت', '##يج', '##ة', '3', '–', '2', '،', 'في', 'نهائي', 'كأس', 'ال', '##ات', '##حاد', 'ال', '##إن', '##جلي', '##زي', 'ل', '##عام', '1979', '،', 'بمب', '##ارا', '##ة', '[UNK]', 'ما', '[UNK]', 'ال', '##مع', '##جب', '##ون', 'مبارا', '##ة', 'كلاسيكي', '##ة', '.']\n",
      "length of encoding: 191\n",
      " number of words around splitted spaces : 85\n",
      "number of tokens that are not in the vocab: 0\n",
      "تتغذى صغار الثدييات كافة بالحليب الذي تحصل عليه من أثداء الأمهات. وترضع صغار كل من ذوات المشيمة وذوات الجراب من حلمات الثدي. أما الإناث وحيدة المسلك فليست لها حلمات بل تفرز لبنها من خلال ثقوب موجودة على سطح البطن وتلعقه الصغار. وتستمر فترة حضانة الصغار أسابيع قليلة فقط في كل من الفئران والأرانب البرية وأنواع أخرى عديدة. ولكن في بعض الثدييات مثل الفيلة والكركدن ترضع الصغار لعدة أعوام قبل أن تفطم. وفي معظم الأنواع تستطيع الصغار أن تتغذى بالأطعمة الصلبة وذلك لفترات طويلة قبل الفطام.\n",
      "\n",
      "['تتغذ', '##ى', 'صغار', 'ال', '##ث', '##دي', '##ي', '##ات', 'كاف', '##ة', 'ب', '##ال', '##حل', '##يب', 'الذي', 'تحصل', 'علي', '##ه', 'من', 'أثداء', 'ال', '##أم', '##ها', '##ت', '.', 'وتر', '##ضع', 'صغار', 'كل', 'من', 'ذوات', 'ال', '##مش', '##يم', '##ة', 'و', '##ذو', '##ات', 'ال', '##جر', '##ا', '##ب', 'من', 'حلم', '##ات', 'ال', '##ث', '##دي', '.', 'أما', 'ال', '##إن', '##اث', 'وحيد', '##ة', 'ال', '##مس', '##لك', 'فلي', '##ست', 'ل', '##ها', 'حلم', '##ات', 'بل', 'تفرز', 'لبن', '##ها', 'من', 'خلال', 'ثقوب', 'موجود', '##ة', 'على', 'سطح', 'ال', '##بط', '##ن', 'و', '##تلعق', '##ه', 'ال', '##ص', '##غار', '.', 'و', '##تستمر', 'فتر', '##ة', 'حضان', '##ة', 'ال', '##ص', '##غار', 'أسابيع', 'قليل', '##ة', 'فقط', 'في', 'كل', 'من', 'ال', '##فئ', '##ر', '##ان', 'و', '##ال', '##أر', '##ان', '##ب', 'ال', '##بري', '##ة', 'و', '##أن', '##وا', '##ع', 'أخرى', 'عديد', '##ة', '.', 'و', '##لك', '##ن', 'في', 'بعض', 'ال', '##ث', '##دي', '##ي', '##ات', 'مثل', 'ال', '##في', '##ل', '##ة', 'و', '##ال', '##كر', '##كد', '##ن', 'ترضع', 'ال', '##ص', '##غار', 'ل', '##عد', '##ة', 'أعوام', 'قبل', 'أن', 'تف', '##طم', '.', 'و', '##في', 'معظم', 'ال', '##أن', '##وا', '##ع', 'تستطيع', 'ال', '##ص', '##غار', 'أن', 'تتغذ', '##ى', 'ب', '##ال', '##أ', '##طعم', '##ة', 'ال', '##صل', '##ب', '##ة', 'و', '##ذلك', 'لفت', '##ر', '##ات', 'طويل', '##ة', 'قبل', 'ال', '##فط', '##ام', '.']\n",
      "length of encoding: 150\n",
      " number of words around splitted spaces : 85\n",
      "number of tokens that are not in the vocab: 2\n",
      "قامت مجلة فوربس خلال شهر أبريل من عام 2010، بوضع أرسنال في المرتبة الثالثة ضمن قائمة أغلى نوادي كرة القدم في العالم، بعد مانشستر يونايتد وريال مدريد، حيث قدّرت قيمته بحوالي 1.181 مليار دولار أمريكي (768 مليون جنيه استرليني)، دون احتساب ديونه. أكبر المساهمين في مجلس إدارة أرسنال هو المليونير الأمريكي محب الرياضة، إينوس ستان كروينك، الذي أطلق مزايدة على النادي في عام 2007، واشترى المزيد من الأسهم فيه حتى أصبح كامل نصيبه منها 18,594 سهمًا (29.9% من النادي)، بحلول شهر نوفمبر من عام 2009.\n",
      "\n",
      "['قام', '##ت', 'مجل', '##ة', 'فوربس', 'خلال', 'شهر', 'أبريل', 'من', 'عام', '2010', '،', 'ب', '##وضع', 'أرسنال', 'في', 'ال', '##مر', '##ت', '##ب', '##ة', 'ال', '##ثالث', '##ة', 'ضمن', 'قائم', '##ة', 'أغلى', 'نوادي', 'كر', '##ة', 'ال', '##قدم', 'في', 'ال', '##عالم', '،', 'بعد', 'مانشستر', 'يونايتد', 'و', '##ريال', 'مدريد', '،', 'حيث', '[UNK]', 'قيم', '##ت', '##ه', 'بح', '##وا', '##لي', '1', '.', '181', 'مليار', 'دولار', 'أمريكي', '(', '768', 'مليون', 'جنيه', 'استرليني', ')', '،', 'دون', 'احتساب', 'ديون', '##ه', '.', 'أكبر', 'ال', '##مساهم', '##ين', 'في', 'مجلس', 'إدار', '##ة', 'أرسنال', 'هو', 'ال', '##مليون', '##ير', 'ال', '##أمريكي', 'محب', 'ال', '##رياض', '##ة', '،', 'إينو', '##س', 'ستان', 'كروي', '##نك', '،', 'الذي', 'أطلق', 'مزايد', '##ة', 'على', 'ال', '##نادي', 'في', 'عام', '2007', '،', 'واش', '##ت', '##رى', 'ال', '##مز', '##يد', 'من', 'ال', '##أس', '##هم', 'في', '##ه', 'حتى', 'أصبح', 'كامل', 'نصيب', '##ه', 'من', '##ها', '18', ',', '594', '[UNK]', '(', '29', '.', '9', '%', 'من', 'ال', '##نادي', ')', '،', 'بح', '##لول', 'شهر', 'نوفمبر', 'من', 'عام', '2009', '.']\n",
      "length of encoding: 157\n",
      " number of words around splitted spaces : 86\n",
      "number of tokens that are not in the vocab: 1\n",
      "أول إطلاق لجهاز البلاي ستيشن 3 كان في 11 نوفمبر 2006 في اليابان، وقد قوبل انطلاق الجهاز باصطفاف آلاف اليابانيين لساعات أمام المحلات التي تبيع الجهاز متحدّين بذلك الجو الممطر البارد في ذلك اليوم، وفي أول أربع وعشرين ساعة من انطلاقه في اليابان بيع 81,639 جهاز بلاي ستيشن 3.\n",
      "بعد ستة أيام من إطلاق جهاز البلاي ستيشن 3 في اليابان، أطلقت سوني الجهاز بتاريخ 17 نوفمبر 2006 في أسواق أمريكا الشمالية، وأطلق الجهاز لأول مرة في أوروبا، أستراليا، أفريقيا ونيوزيلندا ومنطقة الشرق الأوسط في 22 مارس 2007.\n",
      "\n",
      "['أول', 'إطلاق', 'لج', '##ها', '##ز', 'ال', '##بل', '##ا', '##ي', 'ستيشن', '3', 'كان', 'في', '11', 'نوفمبر', '2006', 'في', 'ال', '##ياب', '##ان', '،', 'و', '##قد', 'قوبل', 'انطلاق', 'ال', '##جهاز', 'باص', '##طف', '##اف', 'آلاف', 'ال', '##ياب', '##اني', '##ين', 'لس', '##اع', '##ات', 'أمام', 'ال', '##مح', '##لا', '##ت', 'التي', 'تبيع', 'ال', '##جهاز', '[UNK]', 'بذل', '##ك', 'ال', '##جو', 'ال', '##مم', '##طر', 'ال', '##بارد', 'في', 'ذلك', 'ال', '##يوم', '،', 'و', '##في', 'أول', 'أربع', 'و', '##عشر', '##ين', 'ساع', '##ة', 'من', 'انطلاق', '##ه', 'في', 'ال', '##ياب', '##ان', 'بيع', '81', ',', '639', 'جهاز', 'بلاي', 'ستيشن', '3', '.', 'بعد', 'ست', '##ة', 'أيام', 'من', 'إطلاق', 'جهاز', 'ال', '##بل', '##ا', '##ي', 'ستيشن', '3', 'في', 'ال', '##ياب', '##ان', '،', 'أطلق', '##ت', 'سوني', 'ال', '##جهاز', 'ب', '##تاريخ', '17', 'نوفمبر', '2006', 'في', 'أسواق', 'أمريكا', 'ال', '##شمال', '##ي', '##ة', '،', 'و', '##أ', '##طلق', 'ال', '##جهاز', 'لأ', '##ول', 'مر', '##ة', 'في', 'أوروبا', '،', 'أستراليا', '،', 'أفريقيا', 'و', '##نيوز', '##ي', '##لندا', 'و', '##منطق', '##ة', 'ال', '##شرق', 'ال', '##أوس', '##ط', 'في', '22', 'مارس', '2007', '.']\n"
     ]
    }
   ],
   "source": [
    "def show_encoding_of(sentence, tokenizer):\n",
    "    encoding = tokenizer(sentence)\n",
    "    \n",
    "    print('length of encoding:', len(encoding['input_ids']))\n",
    "    print(' number of words around splitted spaces :', len(sentence.split(' ')))\n",
    "    list_of_tokens = []\n",
    "    count_of_unk_tokens = 0\n",
    "    for i in encoding['input_ids']:\n",
    "        #print the decoding of it\n",
    "        list_of_tokens.append(tokenizer.decode([i]))\n",
    "        if(tokenizer.decode([i]) == '[UNK]'):\n",
    "            count_of_unk_tokens +=1\n",
    "    #print the list of tokens\n",
    "    print('number of tokens that are not in the vocab:', count_of_unk_tokens)\n",
    "    print(sentence)\n",
    "    # loop over the list of tokens and print them\n",
    "    # for token in list_of_tokens:\n",
    "    #     display(token)\n",
    "    print(list_of_tokens[1:-1])\n",
    "    # print(encoding)\n",
    "    \n",
    "# test_text = \"الألواح الخشبية تعالج بعد ذلك في أفران للتحميص حتى لا تتأثر مستقبلاً بتغييرات درجات الحرارة أو الرطوبة الموجودة في الجو\"\n",
    "# test_text = \"يوجد في باريس العديد من الملاعب المخصصة لمختلف أنواع الرياضات. يعدّ ملعب فرنسا الذي يتسع لأكثر من 80 ألف متفرج أكبر ملاعب البلاد، وكان قد بني هذا الملعب الواقع في منطقة سان دينس لاستضافة كأس العالم لكرة القدم 1998 والذي حازت عليه فرنسا للمرة الأولى في تاريخها. يستخدم الملعب لممارسة كرة القدم، والرجبي، وألعاب القوى. يستضيف الملعب مباريات منتخب فرنسا الوطني للرجبي سنوياً في بطولة الأمم الستة. وكذلك يستضيف مباريات منتخب فرنسا لكرة القدم الودية وتصفيات البطولات الكبرى. بالإضافة إلى نادي باريس سان جيرمان، تملك المدينة نوادي كرة قدم أخرى مثل: نادي باريس، والنجم الأحمر ونادي فرنسا\"\n",
    "for i in range(5,10):\n",
    "    test_text = train_contexts[i]\n",
    "    show_encoding_of(test_text, arabert_tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = arabert_tokenizer\n",
    "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "150\n",
      "None\n",
      "None\n",
      "None\n",
      "123\n",
      "None\n",
      "None\n",
      "None\n",
      "198\n",
      "None\n",
      "None\n",
      "None\n",
      "20\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "144\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "136\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "40\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "148\n",
      "None\n",
      "None\n",
      "None\n",
      "26\n",
      "None\n",
      "None\n",
      "None\n",
      "213\n",
      "None\n",
      "None\n",
      "None\n",
      "201\n",
      "None\n",
      "None\n",
      "None\n",
      "158\n",
      "140\n",
      "133\n",
      "61\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "54\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "80\n",
      "None\n",
      "83\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "58\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "105\n",
      "None\n",
      "None\n",
      "37\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "18\n",
      "None\n",
      "160\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "19\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "108\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "68\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "121\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "235\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "61\n",
      "None\n",
      "None\n",
      "None\n",
      "11\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "62\n",
      "None\n",
      "None\n",
      "6\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "45\n",
      "None\n",
      "None\n",
      "291\n",
      "None\n",
      "None\n",
      "63\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "21\n",
      "None\n",
      "None\n",
      "None\n",
      "65\n",
      "None\n",
      "None\n",
      "40\n",
      "100\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "198\n",
      "142\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "34\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "147\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "122\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "79\n",
      "None\n",
      "None\n",
      "41\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "10\n",
      "107\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'answer_end'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kewi\\Documents\\GitHub\\NLP-Project\\QA.ipynb Cell 17\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kewi/Documents/GitHub/NLP-Project/QA.ipynb#X34sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     encodings\u001b[39m.\u001b[39mupdate({\u001b[39m'\u001b[39m\u001b[39mstart_positions\u001b[39m\u001b[39m'\u001b[39m: start_positions, \u001b[39m'\u001b[39m\u001b[39mend_positions\u001b[39m\u001b[39m'\u001b[39m: end_positions})\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kewi/Documents/GitHub/NLP-Project/QA.ipynb#X34sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# apply function to our data\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/kewi/Documents/GitHub/NLP-Project/QA.ipynb#X34sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m add_token_positions(train_encodings, train_answers)\n",
      "\u001b[1;32mc:\\Users\\kewi\\Documents\\GitHub\\NLP-Project\\QA.ipynb Cell 17\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kewi/Documents/GitHub/NLP-Project/QA.ipynb#X34sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mprint\u001b[39m(end_positions[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kewi/Documents/GitHub/NLP-Project/QA.ipynb#X34sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m end_positions[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/kewi/Documents/GitHub/NLP-Project/QA.ipynb#X34sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         end_positions[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m encodings\u001b[39m.\u001b[39mchar_to_token(i, answers[i][\u001b[39m'\u001b[39;49m\u001b[39manswer_end\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m-\u001b[39mgo_back)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kewi/Documents/GitHub/NLP-Project/QA.ipynb#X34sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         go_back \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kewi/Documents/GitHub/NLP-Project/QA.ipynb#X34sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# update our encodings object with the new token-based start/end positions\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'answer_end'"
     ]
    }
   ],
   "source": [
    "def add_token_positions(encodings, answers):\n",
    "    # initialize lists to contain the token indices of answer start/end\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i in range(len(answers)):\n",
    "        # append start/end token position using char_to_token method\n",
    "        \n",
    "        # old\n",
    "        # start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
    "        # end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']))\n",
    "        # Mine mah, lol I am sure it must work\n",
    "        start_positions.append(encodings.char_to_token(i, answers[i].get('answer_start', None)))\n",
    "        end_positions.append(encodings.char_to_token(i, answers[i].get('answer_end', None)))\n",
    "\n",
    "        # if start position is None, the answer passage has been truncated\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length\n",
    "        # end position cannot be found, char_to_token found space, so shift one token forward\n",
    "        go_back = 1\n",
    "        print(end_positions[-1])\n",
    "        while end_positions[-1] is None:\n",
    "            end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end']-go_back)\n",
    "            go_back +=1\n",
    "    # update our encodings object with the new token-based start/end positions\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "\n",
    "# apply function to our data\n",
    "add_token_positions(train_encodings, train_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings['start_positions'][0:20]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finetuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
