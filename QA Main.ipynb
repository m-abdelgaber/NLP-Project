{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SdUV8yfrlSR"
      },
      "source": [
        "# Installs and imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIsirzWvrlSa",
        "outputId": "b95d7a3f-ce1a-4f95-a28c-cdee3ae25247"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import json\n",
        "import ijson\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "from transformers import AutoTokenizer\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import nltk\n",
        "import seaborn as sns ,sklearn,gensim\n",
        "from nltk.corpus import stopwords\n",
        "from collections import  Counter\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JqAFIM9rlSc"
      },
      "source": [
        "# Read the data from https://github.com/adelmeleka/AQAD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnWR_SlsrlSc",
        "outputId": "7c9344a2-bd58-4c7b-f22f-a5227fbe235f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "بيونسيه\n",
            "\n",
            "[{'qas': [{'question': 'متى بدأت بيونسي تصبح شعبية؟', 'id': 1, 'answers': [{'text': 'في أواخر التسعينات', 'answer_start': 220}], 'is_impossible': False}, {'question': 'ما هي المجالات التي تنافس عليها بيونسيه عندما كانت تكبر؟', 'id': 2, 'answers': [{'text': 'غناء ورقص', 'answer_start': 173}], 'is_impossible': False}, {'question': 'متى غادرت بيونسي طفل القدر وتصبح مغنية منفردة؟', 'id': 3, 'answers': [{'text': '(2003)،', 'answer_start': 515}], 'is_impossible': False}, {'question': 'في أي مدينة و ولاية نشأت بيونسيه؟', 'id': 4, 'answers': [{'text': 'هيوستن بولاية تكساس،', 'answer_start': 88}], 'is_impossible': False}, {'question': 'في أي عقد أصبحت بيونسي مشهورة؟', 'id': 5, 'answers': [{'text': 'أواخر التسعينات', 'answer_start': 223}], 'is_impossible': False}, {'question': 'في أي مجموعة R&B كانت هي المغنية الرئيسية؟', 'id': 6, 'answers': [{'text': 'دستنيز تشايلد', 'answer_start': 290}], 'is_impossible': False}, {'question': 'ما الألبوم الذي جعلها فنانة معروفة عالميا؟', 'id': 7, 'answers': [{'text': 'Dangerously in Love', 'answer_start': 476}], 'is_impossible': False}, {'question': 'من أدار مجموعة مصير الطفل؟', 'id': 8, 'answers': [{'text': 'ماثيو نولز،', 'answer_start': 332}], 'is_impossible': False}, {'question': 'متى صعدت بيونسي إلى الشهرة؟', 'id': 9, 'answers': [{'text': 'أواخر التسعينات', 'answer_start': 223}], 'is_impossible': False}, {'question': 'ما الدور الذي لعبه بيونسيه في طفل القدر؟', 'id': 10, 'answers': [{'text': 'فنان منفرد ناجح', 'answer_start': 545}], 'is_impossible': False}, {'question': 'ما هو أول ألبوم صدر بيونسيه كفنان منفرد؟', 'id': 11, 'answers': [{'text': 'Dangerously in Love', 'answer_start': 476}], 'is_impossible': False}, {'question': 'متى أطلقت بيونسيه خطير في الحب؟', 'id': 12, 'answers': [{'text': '(2003)،', 'answer_start': 515}], 'is_impossible': False}, {'question': 'كم عدد جوائز Grammy التي فازت بها Beyoncé لأول ألبوم منفرد لها؟', 'id': 13, 'answers': [{'text': 'خمسة', 'answer_start': 604}], 'is_impossible': False}, {'question': 'ماذا كان دور بيونسيه في طفل القدر؟', 'id': 14, 'answers': [{'text': 'فنان منفرد ناجح', 'answer_start': 545}], 'is_impossible': False}, {'question': 'ما هو اسم أول ألبوم منفرد لبيونسي؟', 'id': 15, 'answers': [{'text': 'Dangerously in Love', 'answer_start': 476}], 'is_impossible': False}], 'context': 'بيونسي جيزيل نولز-كارتر (من مواليد 4 سبتمبر، 1981)، المعروفة باسم بيونسي. ولدت ونشأت في هيوستن بولاية تكساس، هي مغنية وممثلة أميركية حائزة على 23 جائزة غرامي.غنت في مسابقات غناء ورقص مختلفة عندما كانت طفلة، أصبحت مشهورة في أواخر التسعينات كمغنية آر أند بي (رئيسية) للفرقة الغنائية النسائية دستنيز تشايلد. والتي أديرت من قِبل والدها ماثيو نولز، وأصبحت الفرقة واحدة من الأكثر مبيعاً في العالم من الفرق النسائية على الإطلاق. وقد شهد إنفصال الفرقة المؤقت صدور ألبوم بيونسي الأول  Dangerously in Love دانجيروسلي إن لوف  (2003)، والذي أنشأها بأن تكون فنان منفرد ناجح في العالم؛ بيعت منه 16 مليون نسخة، حصل على خمسة جوائز غرامي وتضمن الأغاني التي وصلت إلى قمة الرسم البياني الأمريكي بيلبورد هوت 100 \"كريزي إن لوف\" و\"بيبي بوي\". \\n'}, {'qas': [{'question': 'في أي مدينة ذهبت بيونسي إلى المدرسة؟', 'id': 16, 'answers': [{'text': 'فريدريكسبورغ', 'answer_start': 63}], 'is_impossible': False}, {'question': 'من كان أول شخص يلاحظ قدرة بيونسي على الغناء؟', 'id': 17, 'answers': [{'text': 'دارلاتا جونسون', 'answer_start': 128}], 'is_impossible': False}, {'question': 'انتقلت بيونسي إلى أي مدينة بعد أن تركت مدرستها الابتدائية الأولى؟', 'id': 18, 'answers': [{'text': 'هيوستن،', 'answer_start': 849}], 'is_impossible': False}, {'question': 'أي من أساتذتها اكتشفوا موهبة بيونسي الموسيقية؟', 'id': 19, 'answers': [{'text': 'جونسون مدرس الرقص لبيونسي', 'answer_start': 136}], 'is_impossible': False}, {'question': 'أنا الكنيسة التي كانت بيونسيه عضو وعازف منفرد في الجوقة؟', 'id': 20, 'answers': [{'text': 'القديس', 'answer_start': 43}], 'is_impossible': False}, {'question': 'ما نوع المدرسة التي كانت مدرسة باركر الابتدائية؟', 'id': 21, 'answers': [{'text': 'مدرسة أليف السيك،', 'answer_start': 882}], 'is_impossible': False}, {'question': 'ما الأغنية التي غنتها بيونسي للفوز في مسابقة في سن السابعة؟', 'id': 22, 'answers': [{'text': 'من', 'answer_start': 334}], 'is_impossible': False}, {'question': 'في أي مدينة تقع مدرسة بيونسي الابتدائية؟', 'id': 23, 'answers': [{'text': 'فريدريكسبورغ', 'answer_start': 63}], 'is_impossible': False}, {'question': 'ما اسم أول مدرب للرقص في بيونسيه؟', 'id': 24, 'answers': [{'text': 'دارلاتا جونسون', 'answer_start': 128}], 'is_impossible': False}, {'question': 'ما الجوقة التي غنتها بيونسي لمدة عامين؟', 'id': 25, 'answers': [{'text': 'القديس', 'answer_start': 43}], 'is_impossible': False}], 'context': \"حصلت بيونسي على تعليمها الإبتدائي في مدرسة القديس ماري التي في فريدريكسبورغ (تكساس). وحصلت هناك أيضاً على دروس الرقص. وقد اكتشف دارلاتا جونسون مدرس الرقص لبيونسي موهبتها الغنائية عندما بدأت في همهمة تلحين أغنية بصوتها (إحدى الأغنيات)، وقد ضغط عليها حتى تكمل الأغنية. وقد فازت بيونسي في مسابقة للغناء وأداء الصوت عندما كانت في السابعة من عمرها، وباقي المشتركين في الخامسة عشر، والسادسة عشر. وقد قامت بغناء أغنية تخيل للمغن والشاعر وعازف جيتار فرقة البيتلز جون لينون. وهي أغنية تصف عالمًا مثاليًا تتحقق فيه المساواة والسلام بين بني البشر. الأغنية من كلمات جون لينون ومن إخراج فيل سبيكتور. وقد صدرت لأول مرة عام-1971 كجزء من ألبوم إيماجين. وتعد الأغنية واحدة من أفضل الأغاني وأكثرها شيوعًا، وفي عام 2004 حلت في المرتبة الثالثة على قائمة رولينغ ستون لأفضل خمسمائة أغنية في التاريخ. وفي خريف عام 1990، وتنضم بيونسي إلى مدرسة باركر الابتدائية للموسيقى في هيوستن، تكساس. وبعد ذلك ذهبت إلى مدرسة أليف السيك، الثانوية للفنون المسرحية والفنون البصرية. بالإضافة إلى قضائها سنتين كاملتين في مدرسة الكنيسة الميثودية المتحدة St. John's.\\n\"}, {'qas': [{'question': 'من قرر وضع مجموعة بيونسيه في برنامج Star Search في عرض المواهب؟', 'id': 26, 'answers': [{'text': 'آرنى فراجير', 'answer_start': 299}], 'is_impossible': False}, {'question': 'من كان أول علامة سجل لإعطاء الفتيات صفقة قياسية؟', 'id': 27, 'answers': [{'text': 'مع إلكترا', 'answer_start': 829}], 'is_impossible': False}, {'question': 'من الذي أحضر بيونسي إلى كاليفورنيا ودخل مجموعتها في Star Search؟', 'id': 28, 'answers': [{'text': 'آرنى فراجير', 'answer_start': 299}], 'is_impossible': False}, {'question': 'في أي عام ترك والد بيونسي وظيفته لإدارة مجموعتها؟', 'id': 29, 'answers': [{'text': '1995', 'answer_start': 527}], 'is_impossible': False}, {'question': 'ما هي شركة التسجيلات الكبيرة التي سجلت أول ألبوم لمجموعة بيونسيه؟', 'id': 30, 'answers': [{'text': 'سوني للموسيقى', 'answer_start': 1173}], 'is_impossible': False}, {'question': 'ما شركة تسجيل وقعت لأول مرة مجموعة بيونسي وقطعت في وقت لاحق لهم؟', 'id': 31, 'answers': [{'text': 'مع إلكترا', 'answer_start': 829}], 'is_impossible': False}, {'question': 'من وضع Tyme الفتاة في البحث عن النجوم؟', 'id': 32, 'answers': [{'text': 'آرنى فراجير', 'answer_start': 299}], 'is_impossible': False}, {'question': 'من وقع على مجموعة الفتاة في 5 أكتوبر 1995؟', 'id': 33, 'answers': [{'text': 'للتسجيلات في', 'answer_start': 839}], 'is_impossible': False}], 'context': 'وتقابلت بيونسي وصديقة طفولتها كيلي رولاند مع لا تفيا روبرسون في انتخابات مجموعات التسلية والترفيه التي تكونت من تجمع فتيات في عمر الثمانية. وقاموا بإنشاء مجموعة مع ثلاث فتيات آخريات وأسسوها بعنوان فتاة التيمي وقاموا بالرقص وغناء الراب في نطاق مسابقة المواهب في هيوستن. وبعد الإطلاع على المجموعة قام آرنى فراجير منتج R&B بإحضار الفتيات إلى الإستوديو في شمال كاليفورنيا، وفي ذلك الوقت شاركوا في مسابقة (البحث عن نجم) أكبر مسابقة مواهب عُرضت على شاشة التلفاز. وقامت بيونسي بأداء أغنية في مسابقة فتاة التيمي ولكنها لم تفز. وفي عام 1995 غادر والد بيونسي إدارة المجموعة. ونتيجة لذلك فقد حدّ دخل عائلة بيونسي واضطر كل من والدها ووالدتها الانتقال إلى شقق منفصلة. وانخفض مستوى مجموعة ماثيو المبتكر إلى الترتيب الرابع واستمرت هذه المجموعة في الظهور على المسرح وحتى من قبل ظهور مجموعة الفتيات R&B المعروفين. وقامت هذه المجموعة بعقد إتفاقية مع إلكترا للتسجيلات في عام 1995 وبعد وقت لاحق من هذه الإتفاقية تم إنهاؤها من قبل الشركة، وأدى هذا الحدث إلى زيادة التوتر في العائلة وانفصل والديّ بيونسي. وفي الخامس من شهر أكتوبر عام 1995 قامت الشعبية الترفيهية صاحبة دويني ويغينز بعقد إتفاقية مع الفتيات. وفي عام 1996 بدأت المجموعة بتسجيل ألبومها الأول في إطار الإتفاقية والذي قام بإنتاجه شركة سوني للموسيقى. وتوحدت أسرة نولز من جديد وبعد فترة ما وقعت الفتيات إتفاقية جديدة مع كولومبيا للتسجيلات.\\n'}, {'qas': [{'question': '\"الملائكة تشارلي\" ظهرت أي واحد من أعضاء الفرقة؟', 'id': 34, 'answers': [{'text': 'بيعت منه أكثر', 'answer_start': 1007}], 'is_impossible': False}, {'question': 'باع ألبومهم الثالث ، Survivor ، كم خلال أسبوعه الأول؟', 'id': 35, 'answers': [{'text': 'نسخة', 'answer_start': 1032}], 'is_impossible': False}, {'question': 'ما هو الملحن الفرنسي الذي كتب الأوبرا الأصلية \"كارمن\" في القرن التاسع عشر؟', 'id': 36, 'answers': [{'text': 'جيمس', 'answer_start': 367}], 'is_impossible': False}, {'question': 'النساء المستقلات الجزء الأول كان على 2000 فيلم موسيقى؟', 'id': 37, 'answers': [{'text': 'ساشا فيرس', 'answer_start': 438}], 'is_impossible': False}, {'question': 'ما الفيلم الذي نجحت بيونسي في إنتاجه عام 2001 مع Mekhi Phifer؟', 'id': 38, 'answers': [{'text': 'من قِبل', 'answer_start': 976}], 'is_impossible': False}, {'question': 'متى أعلن مصير الطفل عن توقفه؟', 'id': 39, 'answers': [{'text': 'فيرس (2008)،', 'answer_start': 443}], 'is_impossible': False}], 'context': 'بعد انفصال دستنيز تشايلد في 2005، أصدرت ألبومها الإستديو الثاني المنفرد بي دي (2006)، والذي تضمن الأغاني التي نجحت عالمياً \"أيربليسبل\" و\"بيوتفل لاير\". بيونسي معروفة في التمثيل أيضاً، مع أدائها الذي ترشح لجائزة جولدن جلوب في دريم قيرلز (2006). وأدوار بطولة أخرى في ذا بينك بانتر (2006) وأوبسيسد (2009). وتزوجت من مغني الراب جي-زي وتجسيدها للشخصية المغنية الراحلة إيتا جيمس في كاديلاك ريكوردز (2008) أثر على ألبومها الإستديو الثالث، آيم... ساشا فيرس (2008)، والذي شهد ولادة الشخصية البديلة ساشا فيرس وحصل الألبوم على ستة جوائز غرامي في 2010، بما في ذلك أغنية السنة لأغنية \"سنقل ليديز (بوت آ رينق أون إت)\". أخذت بيونسي إجازة من عالم الفن في عام 2010 وتولت إدارة حياتها المهنية، أصدرت ألبومها الإستديو الرابع 4 (2011) الذي كان يحتوي على نبرة ناضجة أكثر من ألبوماتها السابقة، واستكشفت موسيقى الفانك الذي كان في السبعينات مع هذا الألبوم، والبوب في الثمنينات والسول التسعينات، كما أن ألبوم \\'4\\' تسرب بشكل كامل قبل صدوره بشكل رسمي مما يجعل الألبوم أكثر ألبوم تم تحميله بشكل غير قانوني من قِبل فنانة أنثى، رغم تسريبه بيعت منه أكثر من 8 مليون نسخة عالمياً  ألبومها الإستديو الخامس، بيونسي (2013)، تلقى الألبوم على الكثير من المراجعات الإيجابية من نقاد الموسيقى وفضلوه على ألبوماتها السابقة بسبب نوع الألبوم المظلم، كما أن الألبوم تم صدوره بشكل مفاجئ وبيعت منه 828,773 نسخة عالمياً في أول ثلاث أيام من صدوره من دون أي ترويج مسبق.\\n'}, {'qas': [{'question': 'كم عدد نسخ ألبوماتها التي باعتها بيونسي في الولايات المتحدة؟', 'id': 40, 'answers': [{'text': 'مليون', 'answer_start': 221}], 'is_impossible': False}, {'question': 'إجمالي في جميع أنحاء العالم ، كم عدد السجلات التي بيعت بيونسيها؟', 'id': 41, 'answers': [{'text': 'مليون', 'answer_start': 221}], 'is_impossible': False}, {'question': 'عندما كانت بيونسيه مع Destiny Child ، كم عدد الألبومات التي تمكنت من بيعها؟', 'id': 42, 'answers': [{'text': 'و60 مليون', 'answer_start': 275}], 'is_impossible': False}, {'question': 'من كانت أول امرأة تحصل على جائزة الفنان العالمي في جوائز الموسيقى الأمريكية؟', 'id': 43, 'answers': [{'text': 'بيونسي', 'answer_start': 400}], 'is_impossible': False}, {'question': 'كم عدد الألبومات التي بيعت بيونسي كفنان منفرد في الولايات المتحدة؟', 'id': 44, 'answers': [{'text': 'مليون', 'answer_start': 221}], 'is_impossible': False}, {'question': 'كم باعت في جميع أنحاء العالم؟', 'id': 45, 'answers': [{'text': 'مليون', 'answer_start': 221}], 'is_impossible': False}, {'question': \"كم عدد السجلات التي باعتها مع Destiny's Child؟\", 'id': 46, 'answers': [{'text': 'و60 مليون', 'answer_start': 275}], 'is_impossible': False}, {'question': 'متى حصلت على جائزة الأسطورة؟', 'id': 47, 'answers': [{'text': 'جوائز موسيقى', 'answer_start': 103}], 'is_impossible': False}, {'question': 'كم عدد السجلات التي باعتها بيونسيه في الولايات المتحدة؟', 'id': 48, 'answers': [{'text': 'أكثر من 200 مليون', 'answer_start': 209}], 'is_impossible': False}, {'question': 'كم عدد السجلات التي باعها بيونسيه في جميع أنحاء العالم؟', 'id': 49, 'answers': [{'text': 'أكثر من 200 مليون', 'answer_start': 209}], 'is_impossible': False}, {'question': 'متى حصلت بيونسيه على جائزة الأسطورة؟', 'id': 50, 'answers': [{'text': 'جوائز موسيقى', 'answer_start': 103}], 'is_impossible': False}], 'context': 'وحصلت على 23 جائزة غرامي وهي المرأة الأكثر ترشيحًا في تاريخ الجائزة، وهي أيضًا الفنانة الأكثر حصدًا في جوائز موسيقى فيديو MTV ، مع 24 فوزًا ،  وأكثر من 600 جائزة طوال حياتها المهنية التي امتدت 16 عاماً، وباعت أكثر من 200 مليون نسخة من الألبومات والأغاني المنفردة كفنان منفرد و60 مليون مع دستنيز تشايلد، مما يجعلها واحدة من أفضل الفنانين مبيعاً على الإطلاق. أعترفت جمعية صناعة التسجيلات الأمريكية بأن بيونسي أعلى فنان معتمد في أمريكا خلال العقد 2000s. في 2009، سميت بيلبورد بيونسي أعلى فنان راديو لهذا العقد، أعلى فنانة من عقد 2000s وفنان الألفية من قبل بيلبورد في عام 2011. في 2014، أدرجت تايم بيونسي واحدة من أكثر 100 شخصية مؤثرة في العالم.\\n'}]\n"
          ]
        }
      ],
      "source": [
        "with open('AQAD-master\\AQQAD 1.0\\FINAL_AAQAD-v1.0.json','rb') as f:\n",
        "  data = json.load(f)\n",
        "\n",
        "for allData in data['data']:\n",
        "    print(allData['title']+\"\\n\")\n",
        "    print(allData['paragraphs'])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnNQ2IMlrlSd"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "688ROg4DrlSe"
      },
      "outputs": [],
      "source": [
        "def parse_data(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        squad_dict = json.load(f)\n",
        "\n",
        "    # initialize lists for contexts, questions, and answers\n",
        "    contexts = []\n",
        "    questions = []\n",
        "    answers = []\n",
        "    # iterate through all data in squad data\n",
        "    counter = 0\n",
        "    for group in squad_dict['data']:\n",
        "        for passage in group['paragraphs']:\n",
        "            context = passage['context']\n",
        "            for qa in passage['qas']:\n",
        "                question = qa['question']\n",
        "                if 'plausible_answers' in qa.keys():\n",
        "                    access = 'plausible_answers'\n",
        "                else:\n",
        "                    access = 'answers'\n",
        "                for answer in qa[access]:\n",
        "                    counter+=1\n",
        "                    # append data to lists\n",
        "                    contexts.append(context)\n",
        "                    questions.append(question)\n",
        "                    answers.append(answer)\n",
        "    # return formatted data lists\n",
        "    print(counter)\n",
        "    return contexts, questions, answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCk3MeRtrlSf",
        "outputId": "54b63b46-8a56-4732-99c0-516bc746b417"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17896\n"
          ]
        }
      ],
      "source": [
        "contexts, questions, answers = parse_data('AQAD-master\\AQQAD 1.0\\FINAL_AAQAD-v1.0.json')\n",
        "#splitting the data into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_contexts, val_contexts, train_questions, val_questions, train_answers, val_answers = train_test_split(contexts, questions, answers, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "id": "S2Xsrk0jrlSh",
        "outputId": "4b5ecfbc-5481-4e5a-e739-3a9e3ebda309"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14316\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['ما هي أكبر القطاعات الاقتصادية في برمودا؟',\n",
              " 'من الذي أرسل ليحل محل المواقف المطرودة؟',\n",
              " 'كم سنة يمكن تخزين الذاكرة على المدى القصير؟']"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14316\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'text': 'التأمين وإعادة التأمين والسياحة،', 'answer_start': 25},\n",
              " {'text': 'الروس', 'answer_start': 192},\n",
              " {'text': 'من', 'answer_start': 24}]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14316\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['ويستند اقتصاد برمودا على التأمين وإعادة التأمين والسياحة، وهما أكبر قطاعين اقتصاديين في الجزيرة. وكانت برمودا صاحبة إحدى أعلى معدلات الناتج المحلي الإجمالي للفرد في العالم في معظم سنوات القرن العشرين ولعدة سنوات بعدها. تأثر وضعها الاقتصادي في الآونة الأخيرة بسبب الركود العالمي. مناخ الجزيرة هو شبه استوائي. وبرمودا هي أقصى نقطة في شمال مثلث برمودا، وهي منطقة من البحر اختفت فيها عدة سفن وطائرات في ظروف غامضة كما تقول الأسطورة. تقع الجزيرة في حزام الأعاصير وهي عرضة للرياح العاتية. ومع ذلك، فهي محمية نوعا ما من كامل القوة التدميرية للأعاصير بفضل الشعاب المرجانية المحيطة بها.\\n',\n",
              " 'أسفرت جولتين من عمليات التطهير السوفييتية إخراج موسكو (1927-1934 و1937-1938) في طرد ما يقرب من 10،000 شخص من جميع مستويات الحزب الشيوعي في طاجيكستان. أرسلت أصل روسي في ليحلوا محل طرد وبعد ذلك الروس يهيمن مواقف الحزب على جميع المستويات، بما في ذلك المرتبة الأولى من السكرتير الأول. بين 1926 و 1959 ارتفعت نسبة الروس بين سكان طاجيكستان من أقل من 1٪ إلى 13٪. كان ببج غافوروف، السكرتير الأول للحزب الشيوعي في طاجيكستان خلال الفترة من 1946-1956 طاجيكستان السياسي سوموني الوحيد ذو الأهمية خارج البلاد خلال الحقبة السوفيتية. وتبعه في منصبه تورسون الجبيف (1956-1961)، جابر رسولوف (1961-1982)، وعلي رحمان نبييف (1982-1985، 1991-1992).\\n',\n",
              " 'يفرق المختصون بين نوعين من النسيان: نوع تختفي معه المعلومات. وفي النوع الثاني لا تكون المعلومات قد اختفت كلية وإنما يصعب التوصل إليها بسبب تراكم معلومات جديدة عليها. والمهم في ذلك أن تكون المعلومات قد انتقلت من الذاكرة المؤقتة القصيرة إلى الذاكرة الطويلة، إذ أن كل الانطباعات والمعلومات تخزن أولا في الذاكرة القصيرة المؤقتة حيث ينشط تبادل إشارات كهربية بين نحو 100 مليار من الخلايا العصبية. وينشط كل انطباع مجموعة معينة من النيرونات. إلا أن الذاكرة القصيرة لها سعة محدودة على الاحتفاظ بالمعلومات بحيث تأخذ معلومات جديدة مكان معلومات قبلها مثل السبورة التي تكتب وتمسح ثم تُكتب من جديد. ويصل جزء قليل من تلك المعلومات والانطباعات إلى الذاكرة الطويلة، بينما يضيع الجزء الآخر ويُنسى. \\n']"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------\n",
            "3580\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['ماذا يجب أن يحدث إذا ركزت فقط على إرضاء الذات؟',\n",
              " 'ما هي الأعراض التي ستحدث إذا تسبب مرض السل في تمدد الأوعية الدموية في راسموسن؟',\n",
              " 'ما ينمو على نقل الأنهار الجليدية في ألاسكا؟']"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3580\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'text': 'بيد أن القاعدة التي يتم خرقها ربما لا تكون', 'answer_start': 330},\n",
              " {'text': 'نزف', 'answer_start': 367},\n",
              " {'text': 'النباتات', 'answer_start': 73}]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3580\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['إن فعل العصيان المدني هو خرق واع ومتعمد للقانون. كما أنه انتهاك لقاعدة قانونية وضعية. فإذا كان الانتهاك يقوم على القاعدة محل الخلاف مباشرة، فنحن بصدد الحديث عن عصيان مباشر. وهذا هو الحال، على سبيل المثال، بالنسبة لحملة العصيان المدني التي أطلقها مارتن لوثر كينغ والتي كانت تهدف إلى شغل السود للأماكن المخصصة بمقتضى للقانون للبيض. بيد أن القاعدة التي يتم خرقها ربما لا تكون هي تلك محل الخلاف، وحينئذ يكون الحديث عن عصيان مدني غير مباشر، وهو الحال- على سبيل المثال- بالنسبة للاعتصامات التي لا تهدف إلى الاحتجاج على قانون المرور.\\nوعلى الرغم من عدم إمكانية إدراك وجود خرق مسبق (فالقاضي وحده هو الذي يحدد وجود خرق من عدمه)، فإن أي فعل يعد عصيانا مدنيا، عندما يخاطر القائمون عليه بعمل يكون، في نظر الرأي العام ورأي السلطات، خرقا عاما للقانون.\\nوعند التعرض لهذه القضية، يجدر التذكير بالتجربة التي قام بها ستانلي ميلجرام. والتي تمثلت في قياس نسبة الأفراد القادرين على إطلاق مثل هذا العمل الخاص بالعصيان على الرغم من وجود ضغوط اجتماعية وإدارية.\\n',\n",
              " 'إذا تحولت عدوى السل إلى حالة نشطة، فإنها ستُصيب الرئتين على الأغلب (في حوالي 90٪ من الحالات). وقد تشمل الأعراض ألم الصدر والسعال المُنتج للبلغم لفترة طويلة. حوالي 25٪ من الناس المُصابين قد لا تظهر لديهم أي أعراض (أي أنهم يبقون \"لا عرضيين\")  أحيانًا، قد يُصاب المرضى بالسعال المدمى بكميات صغيرة، وفي حالات نادرة جدًا، قد تُسبب العدوى تآكل الشريان الرئوي، مما يؤدي إلى نزف غزير (أم دم راسموسن). قد يُصبح السلّ مرضًا مُزمنًا ويسبب تندبًا واسعًا في الفصوص العلوية من الرئتين.. تتأثر فصوص الرئة العلوية بالسل أكثر من الفصوص السُفلية  ويُعتبر سببُ هذا الاختلاف ليس واضحًا بشكل كامل. وقد يكون إما بسبب تدفق الهواء بشكل أفضل،  أوبسبب ضعف التصريف الليمفاوي ضمن الأجزاء العلوية من الرئتين.\\n',\n",
              " 'تتميز بيئة الجليدة بانخفاض درجة الحرارة فيها إلى المستوى الذي يحد من نمو النباتات ، كما يوقف التنوع الحيواني ، وتتكون رواسب الجليدة عادة من الرواسب الفتاتية ، التي يتراوح حجمها بين الكتل الضخمة التي تصل لحجم المنزل وحجم حبيبات الطفل ، ولذا يندر وجود أحياء بها .\\n']"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(len(train_questions))\n",
        "display(train_questions[0:3])\n",
        "print(len(train_answers))\n",
        "display(train_answers[0:3])\n",
        "print(len(train_contexts))\n",
        "display(train_contexts[0:3])\n",
        "print('-----------------------------------------')\n",
        "print(len(val_questions))\n",
        "display(val_questions[0:3])\n",
        "print(len(val_answers))\n",
        "display(val_answers[0:3])\n",
        "print(len(val_contexts))\n",
        "display(val_contexts[0:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwMe66JgrlSi"
      },
      "source": [
        "## Preprocessing the dataset using arabert in addition to this SQuAD preprocessing guide https://www.youtube.com/watch?v=ZIRmXkHp0-c&t=287s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OtKL075frlSj"
      },
      "outputs": [],
      "source": [
        "def add_end_idx(answers, contexts):\n",
        "    # loop through each answer-context pair\n",
        "    for answer, context in zip(answers, contexts):\n",
        "      # gold_text refers to the answer we are expecting to find in context\n",
        "      gold_text = answer['text']\n",
        "      # we already know the start index\n",
        "      start_idx = answer['answer_start']\n",
        "      # and ideally this would be the end index...\n",
        "      end_idx = start_idx + len(gold_text)\n",
        "      # ...however, sometimes squad answers are off by a character or two\n",
        "      if context[start_idx:end_idx] == gold_text:\n",
        "        # if the answer is not off :)\n",
        "        answer['answer_end'] = end_idx\n",
        "      else:\n",
        "        for n in [1, 2]:\n",
        "            if context[start_idx+n:end_idx+n] == gold_text:\n",
        "                # this means the answer is off by 'n' tokens\n",
        "                answer['answer_start'] = start_idx + n\n",
        "                answer['answer_end'] = end_idx + n\n",
        "                \n",
        "add_end_idx(train_answers, train_contexts)\n",
        "add_end_idx(val_answers, val_contexts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "qNoMJ_BRrlSk",
        "outputId": "7d06a7db-6f9c-4da4-9b63-25921bfff8c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before dropping:\n",
            "14316\n",
            "14316\n",
            "14316\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'answers without answer_end key:'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'non matching answers:'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'answers without answer_end key:'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'non matching answers:'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dropping 0 indices from train\n",
            "14316\n",
            "14316\n",
            "14316\n",
            "dropping 0 indices from train\n",
            "3580\n",
            "3580\n",
            "3580\n"
          ]
        }
      ],
      "source": [
        "#loop over answers, and contexts and make sure that they match\n",
        "def check_answers_contexts_match_and_find_anomalies(answers, contexts, questions, show_anomalies=False):\n",
        "    \n",
        "    answers_without_answer_end_key =0\n",
        "    non_matching_answers=0\n",
        "    indices_of_answers_without_answer_end_key = []\n",
        "    for answer, context, question in zip(answers, contexts, questions):\n",
        "        \n",
        "        #check if context has key answer_end and if not \n",
        "        if 'answer_end' not in answer.keys():\n",
        "            answers_without_answer_end_key +=1\n",
        "            if show_anomalies:\n",
        "                print(question)\n",
        "                print(answer)\n",
        "                print(context[answer['answer_start']:answer['answer_start']+ len(answer['text'])+1])\n",
        "            indices_of_answers_without_answer_end_key.append(answers.index(answer))\n",
        "\n",
        "            continue \n",
        "\n",
        "        #check if answer matches context\n",
        "        if context[answer['answer_start']:answer['answer_end']] != answer['text']:\n",
        "            non_matching_answers +=1\n",
        "    display('answers without answer_end key:', answers_without_answer_end_key,'non matching answers:', non_matching_answers)\n",
        "    return indices_of_answers_without_answer_end_key\n",
        "\n",
        "\n",
        "print(\"before dropping:\")\n",
        "print(len(train_questions))\n",
        "print(len(train_answers))\n",
        "print(len(train_contexts))\n",
        "\n",
        "indices_to_drop1 = check_answers_contexts_match_and_find_anomalies(train_answers, train_contexts, train_questions, True)\n",
        "#drop the answers, contexts and questions that do not match the context\n",
        "train_answers = [i for j, i in enumerate(train_answers) if j not in indices_to_drop1]\n",
        "train_contexts = [i for j, i in enumerate(train_contexts) if j not in indices_to_drop1]\n",
        "train_questions = [i for j, i in enumerate(train_questions) if j not in indices_to_drop1]\n",
        "indices_to_drop2 = check_answers_contexts_match_and_find_anomalies(val_answers, val_contexts, val_questions)\n",
        "#drop the answers, contexts and questions that do not match the context\n",
        "val_answers = [i for j, i in enumerate(val_answers) if j not in indices_to_drop2]\n",
        "val_contexts = [i for j, i in enumerate(val_contexts) if j not in indices_to_drop2]\n",
        "val_questions = [i for j, i in enumerate(val_questions) if j not in indices_to_drop2]\n",
        "# print length of data after dropping\n",
        "\n",
        "print(\"dropping\",len(indices_to_drop1), \"indices from train\")\n",
        "\n",
        "print(len(train_questions))\n",
        "print(len(train_answers))\n",
        "print(len(train_contexts))\n",
        "\n",
        "print(\"dropping\",len(indices_to_drop2), \"indices from train\")\n",
        "print(len(val_questions))\n",
        "print(len(val_answers))\n",
        "print(len(val_contexts))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvJX6N-brlSl"
      },
      "source": [
        "dropping the triplets which don't have answer_end in their answers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f8hfHGjrlSl"
      },
      "source": [
        "## Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "877c929bcb544615823588a2331e777a",
            "182f88c03556458f99d131a05f669428",
            "1a2b73653c414700b9ad6e025cea4cec",
            "283ad12349a04b6098c3b7fb0ff059f9",
            "7007b5312eb14f6b950a41b9cf8ef35d",
            "c71af7dbc4cf46e7bbf8262925fa5f41",
            "1226da27fe514e1780844c2bac6561c6",
            "26d17baf11d341c6bec339cddc8e7e12",
            "dc034347a3704bda8d3ff402f481441c",
            "6945f0db30ed4efeaaf197e78a2a6495",
            "5bee9ea299c640fd86f525b474249e3c",
            "95c6781289b64a3db1dd364d11c616e7",
            "c3073fe7da3f42daa0186f881eafff5a",
            "79650a9b9d7e43eb8317b77915f0a1c6",
            "adc9eb70f17648bbb564e2d933d3874e",
            "6b250c6ab34d4f5db09bfd2d42c8626c",
            "d9141616ee6e418997257e31d0575d3a",
            "9e68b4ce93474acfb0cab00a1457aa00",
            "0189149c653542b18af29a72f337a296",
            "71fd70e4960149628eef41f9b61def34",
            "3c1a0e5bbdb44208a288638b05ca6cd6",
            "ab9aa109770045e3a156dc87053de4a0",
            "e6323fc8cbbc416286dbadd69d95baad",
            "c89f28bd39764446a743291ac0ee79c5",
            "7eae82df839b4f49882c25b6f8196be2",
            "e795b00ba6bb4734b3ebd3bfa27e6d3b",
            "7acfa42bf35149948c7ff8215ff92529",
            "d75ef1d79de34adab125acab8b9207fc",
            "cbf5eb602e08443ea0484d828337900f",
            "63efd25c6410466d976aad803f53f897",
            "2f831e284d854b8db5fda93454f11cf2",
            "80225c74ac2949fdbad4a79952859944",
            "967c3bbd01794ed29a1006c86a5de7ee",
            "eb7b6ccb53d147fe90486f23571c73a9",
            "329a2ab616874c7284d84a89e5e901df",
            "b794a7ed5cfa48869cc66c9558bd81c0",
            "66405b5df8ab44bfa498ff080dd530f4",
            "25437c4fb55341bd8fb13beef8118421",
            "59d661c98ada4778a3ce9efe729b3997",
            "6c474507d57d459595685c6034e23454",
            "f23d1f1e11ec401993ee26489b00370d",
            "07ca26fe07e248fa9a9954ba10410d72",
            "280d3dfdaf204a43a556bc1d2f33228e",
            "b320aadc6edf47448e8900b3ebd95d28",
            "1d5bd38c6e8649feaf03993a9529a9d3",
            "14ab6f4a79d845dfb4a4dfdb3064b54c",
            "08e03b0a847f4e589e2088ec8a91ec4b",
            "67a364467c69448da3a615cbff44eaaa",
            "37310c5ad6e840c5ba16ccb9c17a4f4c",
            "f231d7196a054148bdbac98926e4a3cf",
            "582370614edb443888dec80fe6d962a4",
            "0a43fd56b91b4cc7bfee68915b4423fd",
            "41d3b87964fa4dd499e7581f8c9c2081",
            "471069fec4594096916f8b9d7e4c6ef7",
            "2f5a3096a800456b97e2a1f52425d061"
          ]
        },
        "id": "6scHkGm1rlSm",
        "outputId": "8fc0a95c-183a-40e4-b0c1-a6fc2e8f0775"
      },
      "outputs": [],
      "source": [
        "# old\n",
        "arabert_tokenizer = AutoTokenizer.from_pretrained(\"aubmindlab/bert-base-arabert\",\n",
        "                                                    do_lower_case=False,\n",
        "                                                    do_basic_tokenize=True,\n",
        "                                                    remove_html_markup = False,\n",
        "                                                    strip_tashkeel = True,\n",
        "                                                    strip_tatweel = True,\n",
        "                                                    keep_emojis = True,\n",
        "                                                    insert_white_spaces = True,\n",
        "                                                    replace_slash_with_dash = True,\n",
        "                                                    apply_farasa_segmentation = False)\n",
        "\n",
        "# new \n",
        "# arabert_tokenizer = AutoTokenizer.from_pretrained(\"aubmindlab/bert-base-arabert\",\n",
        "#                                                     do_lower_case=True,\n",
        "#                                                     do_basic_tokenize=True,\n",
        "#                                                     remove_html_markup = False,\n",
        "#                                                     strip_tashkeel = True,\n",
        "#                                                     strip_tatweel = True,\n",
        "#                                                     keep_emojis = True,\n",
        "#                                                     insert_white_spaces = True,\n",
        "#                                                     replace_slash_with_dash = True,\n",
        "#                                                     apply_farasa_segmentation = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Pk8rF_-frlSo"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50f8167d09374a2fa4385a7dc4d14295",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c02eea463824bc88c3d76e2863041e4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1ce7152506443e3aadb50c6159de0eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# tokenizer = arabert_tokenizer\n",
        "from transformers import DistilBertTokenizerFast\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-multilingual-cased')\n",
        "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-LWp0NLrlSm",
        "outputId": "e4ee6c52-06d7-4974-b0dc-581b7d7213ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of encoding: 199\n",
            "number of words around splitted spaces : 96\n",
            "number of tokens that are not in the vocab: 0\n",
            "['و', '##يس', '##تن', '##د', 'اقتصاد', 'بر', '##مو', '##دا', 'على', 'ال', '##ت', '##أمين', 'و', '##إ', '##عادة', 'ال', '##ت', '##أمين', 'و', '##ال', '##سي', '##احة', '،', 'وهم', '##ا', 'أكبر', 'ق', '##طاع', '##ين', 'اقتصاد', '##يين', 'في', 'الجزيرة', '.', 'وكانت', 'بر', '##مو', '##دا', 'صاحب', '##ة', 'إحدى', 'أعلى', 'معدل', '##ات', 'ال', '##نات', '##ج', 'ال', '##م', '##حلي', 'ال', '##إ', '##جمالي', 'ل', '##لف', '##رد', 'في', 'العالم', 'في', 'معظم', 'سنوات', 'القرن', 'العشرين', 'و', '##ل', '##عدة', 'سنوات', 'بعدها', '.', 'ت', '##أثر', 'وضع', '##ها', 'ال', '##اق', '##ت', '##صاد', '##ي', 'في', 'ال', '##آ', '##ونة', 'الأخيرة', 'بسبب', 'ال', '##ر', '##كو', '##د', 'العالمي', '.', 'من', '##اخ', 'الجزيرة', 'هو', 'شبه', 'است', '##وا', '##ئي', '.', 'وب', '##رم', '##ود', '##ا', 'هي', 'أ', '##قصى', 'نقطة', 'في', 'شمال', 'مثل', '##ث', 'بر', '##مو', '##دا', '،', 'وهي', 'منطقة', 'من', 'البحر', 'ا', '##خت', '##فت', 'فيها', 'عدة', 'س', '##فن', 'و', '##طائرات', 'في', 'ظ', '##روف', 'غ', '##ام', '##ضة', 'كما', 'ت', '##قول', 'ال', '##أس', '##طور', '##ة', '.', 'تقع', 'الجزيرة', 'في', 'ح', '##زام', 'ال', '##أ', '##عا', '##صير', 'وهي', 'عرض', '##ة', 'ل', '##لر', '##يا', '##ح', 'ال', '##عات', '##ية', '.', 'ومع', 'ذلك', '،', 'فهي', 'م', '##حم', '##ية', 'نوع', '##ا', 'ما', 'من', 'كامل', 'القوة', 'ال', '##ت', '##دم', '##يرية', 'ل', '##ل', '##أ', '##عا', '##صير', 'ب', '##فضل', 'ال', '##ش', '##عا', '##ب', 'ال', '##مر', '##جان', '##ية', 'المحيطة', 'بها', '.'] \n",
            "\n",
            "length of encoding: 235\n",
            "number of words around splitted spaces : 102\n",
            "number of tokens that are not in the vocab: 0\n",
            "['أ', '##سفر', '##ت', 'جو', '##لت', '##ين', 'من', 'عمليات', 'ال', '##ت', '##طه', '##ير', 'ال', '##سو', '##في', '##يت', '##ية', 'إخراج', 'م', '##وس', '##كو', '(', '1927', '-', '1934', 'و', '##19', '##3', '##7', '-', '1938', ')', 'في', 'ط', '##رد', 'ما', 'ي', '##قرب', 'من', '10', '،', '000', 'شخص', 'من', 'جميع', 'م', '##ست', '##ويات', 'الحزب', 'ال', '##شي', '##وعي', 'في', 'ط', '##اج', '##يك', '##ستان', '.', 'أ', '##رسل', '##ت', 'أصل', 'روس', '##ي', 'في', 'لي', '##حل', '##وا', 'محل', 'ط', '##رد', 'وبعد', 'ذلك', 'ال', '##روس', 'ي', '##ه', '##يم', '##ن', 'م', '##وا', '##قف', 'الحزب', 'على', 'جميع', 'ال', '##مس', '##تو', '##يات', '،', 'بما', 'في', 'ذلك', 'ال', '##مرت', '##بة', 'الأولى', 'من', 'ال', '##سكر', '##تي', '##ر', 'الأول', '.', 'بين', '1926', 'و', '1959', 'ا', '##رت', '##فع', '##ت', 'نسبة', 'ال', '##روس', 'بين', 'سكان', 'ط', '##اج', '##يك', '##ستان', 'من', 'أقل', 'من', '1', '٪', 'إلى', '13', '٪', '.', 'كان', 'ب', '##ب', '##ج', 'غ', '##اف', '##ورو', '##ف', '،', 'ال', '##سكر', '##تي', '##ر', 'الأول', 'ل', '##لح', '##ز', '##ب', 'ال', '##شي', '##وعي', 'في', 'ط', '##اج', '##يك', '##ستان', 'خلال', 'الفترة', 'من', '1946', '-', '1956', 'ط', '##اج', '##يك', '##ستان', 'السياسي', 'سوم', '##وني', 'ال', '##وحيد', 'ذو', 'ال', '##أ', '##هم', '##ية', 'خارج', 'البلاد', 'خلال', 'الحق', '##بة', 'ال', '##سو', '##في', '##تية', '.', 'و', '##تب', '##عه', 'في', 'منصب', '##ه', 'تو', '##رس', '##ون', 'ال', '##جب', '##يف', '(', '1956', '-', '1961', ')', '،', 'جا', '##بر', 'رسول', '##وف', '(', '1961', '-', '1982', ')', '،', 'و', '##عل', '##ي', 'ر', '##حم', '##ان', 'ن', '##بي', '##يف', '(', '1982', '-', '1985', '،', '1991', '-', '1992', ')', '.'] \n",
            "\n",
            "length of encoding: 234\n",
            "number of words around splitted spaces : 115\n",
            "number of tokens that are not in the vocab: 0\n",
            "['ي', '##فرق', 'ال', '##م', '##خت', '##ص', '##ون', 'بين', 'نوع', '##ين', 'من', 'ال', '##نس', '##يان', ':', 'نوع', 'تخت', '##في', 'معه', 'المعلومات', '.', 'وفي', 'النوع', 'الثاني', 'لا', 'تكون', 'المعلومات', 'قد', 'ا', '##خت', '##فت', 'كلية', 'و', '##إن', '##ما', 'ي', '##ص', '##عب', 'ال', '##تو', '##صل', 'إليها', 'بسبب', 'تر', '##اكم', 'معلومات', 'جديدة', 'عليها', '.', 'و', '##الم', '##هم', 'في', 'ذلك', 'أن', 'تكون', 'المعلومات', 'قد', 'انتقل', '##ت', 'من', 'ال', '##ذاك', '##رة', 'ال', '##م', '##ؤ', '##قت', '##ة', 'ال', '##قص', '##يرة', 'إلى', 'ال', '##ذاك', '##رة', 'ال', '##ط', '##ويل', '##ة', '،', 'إذ', 'أن', 'كل', 'ال', '##ان', '##طب', '##اعات', 'و', '##الم', '##علوم', '##ات', 'ت', '##خ', '##زن', 'أول', '##ا', 'في', 'ال', '##ذاك', '##رة', 'ال', '##قص', '##يرة', 'ال', '##م', '##ؤ', '##قت', '##ة', 'حيث', 'ي', '##نش', '##ط', 'ت', '##با', '##دل', 'إ', '##شار', '##ات', 'ك', '##هر', '##بية', 'بين', 'نحو', '100', 'مل', '##يار', 'من', 'الخلايا', 'ال', '##ع', '##صب', '##ية', '.', 'و', '##ين', '##ش', '##ط', 'كل', 'ان', '##طب', '##اع', 'مجموعة', 'معينة', 'من', 'ال', '##ني', '##رون', '##ات', '.', 'إلا', 'أن', 'ال', '##ذاك', '##رة', 'ال', '##قص', '##يرة', 'لها', 'س', '##عة', 'محدود', '##ة', 'على', 'ال', '##اح', '##ت', '##فاظ', 'با', '##لم', '##علوم', '##ات', 'بحيث', 'ت', '##أخذ', 'معلومات', 'جديدة', 'مكان', 'معلومات', 'قبل', '##ها', 'مثل', 'ال', '##سب', '##ورة', 'التي', 'ت', '##كتب', 'وتم', '##س', '##ح', 'ثم', 'ت', '##ُ', '##كتب', 'من', 'جديد', '.', 'و', '##ي', '##صل', 'جزء', 'ق', '##ليل', 'من', 'تلك', 'المعلومات', 'والا', '##ن', '##طب', '##اعات', 'إلى', 'ال', '##ذاك', '##رة', 'ال', '##ط', '##ويل', '##ة', '،', 'بينما', 'ي', '##ضي', '##ع', 'الجزء', 'الآخر', 'و', '##ي', '##ُ', '##نس', '##ى', '.'] \n",
            "\n",
            "length of encoding: 270\n",
            "number of words around splitted spaces : 96\n",
            "number of tokens that are not in the vocab: 0\n",
            "['تكون', 'ال', '##ب', '##ك', '##تي', '##ريا', 'ال', '##ص', '##ام', '##دة', 'ل', '##لح', '##م', '##ض', '،', 'مثل', '\"', 'ال', '##مت', '##ف', '##طرة', '\"', '،', 'م', '##ضا', '##دة', 'ل', '##إ', '##زال', '##ة', 'ال', '##صب', '##غة', 'من', 'قبل', 'ال', '##أ', '##حم', '##اض', 'خلال', 'إ', '##جراء', 'ال', '##تل', '##وي', '##ن', 'في', 'علم', 'ال', '##أ', '##حياء', '.', 'يعد', 'إ', '##حت', '##وا', '##ء', 'ال', '##مت', '##ف', '##طرة', 'لم', '##حت', '##وى', 'ع', '##ال', '##ٍ', 'من', 'ح', '##م', '##ض', 'ال', '##ما', '##يك', '##ولي', '##ك', 'ال', '##سبب', 'في', 'ن', '##م', '##ط', 'ال', '##تل', '##وي', '##ن', 'من', 'ال', '##ام', '##ت', '##صاص', 'ال', '##ضع', '##يف', 'الذي', 'ي', '##تل', '##وه', 'لا', '##ست', '##بق', '##اء', 'العالي', '.', 'أكثر', 'ط', '##رق', 'ال', '##تل', '##وي', '##ن', 'استعمال', '##اً', 'ل', '##تحديد', 'ال', '##ب', '##ك', '##تي', '##ريا', 'ال', '##ص', '##ام', '##دة', 'ل', '##لح', '##م', '##ض', 'هي', 'تل', '##وي', '##ن', 'ت', '##سي', '##ل', '-', 'ن', '##لس', '##ن', '(', 'أو', 'تل', '##وي', '##ن', 'ص', '##ام', '##د', 'ل', '##لح', '##م', '##ض', ')', '،', 'و', 'الذي', 'ت', '##ُ', '##لو', '##ن', 'فيه', 'ال', '##ع', '##ُ', '##ص', '##يات', 'ال', '##ص', '##ام', '##دة', 'ل', '##لح', '##م', '##ض', 'با', '##لل', '##ون', 'الأحمر', 'ال', '##فاق', '##ع', 'مما', 'ي', '##ُ', '##برز', '##ها', 'بو', '##ض', '##وح', 'ضد', 'خ', '##لف', '##ية', 'ز', '##رق', '##اء', '.', 'ب', '##ك', '##تي', '##ريا', 'أ', '##ل', 'هي', 'س', '##لال', '##ة', 'من', 'ال', '##ب', '##ك', '##تي', '##ريا', 'التي', 'لا', 'تحتوي', 'على', 'جدا', '##ر', 'خ', '##لو', '##ي', '.', 'أ', '##برز', 'أنواع', 'ال', '##ب', '##ك', '##تي', '##ريا', 'ال', '##مع', '##دية', 'في', 'هذه', 'ال', '##طا', '##ئ', '##فة', 'هي', '\"', 'ال', '##م', '##ف', '##طور', '##ة', '\"', '(', 'ي', '##ن', '##ب', '##غي', 'عدم', 'ال', '##خل', '##ط', 'بين', '##ها', 'و', 'بين', '\"', 'ال', '##مت', '##ف', '##طرة', '\"', ')', '.'] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "def show_encoding_of(sentence, tokenizer):\n",
        "    encoding = tokenizer(sentence)\n",
        "    \n",
        "    print('length of encoding:', len(encoding['input_ids']))\n",
        "    print('number of words around splitted spaces :', len(sentence.split(' ')))\n",
        "    list_of_tokens = []\n",
        "    count_of_unk_tokens = 0\n",
        "    for i in encoding['input_ids']:\n",
        "        #print the decoding of it\n",
        "        list_of_tokens.append(tokenizer.decode([i]))\n",
        "        if(tokenizer.decode([i]) == '[UNK]'):\n",
        "            count_of_unk_tokens +=1\n",
        "    #print the list of tokens\n",
        "    print('number of tokens that are not in the vocab:', count_of_unk_tokens)\n",
        "    print(list_of_tokens[1:-1], \"\\n\")\n",
        "    # print(encoding)\n",
        "    \n",
        "# test_text = \"الألواح الخشبية تعالج بعد ذلك في أفران للتحميص حتى لا تتأثر مستقبلاً بتغييرات درجات الحرارة أو الرطوبة الموجودة في الجو\"\n",
        "# test_text = \"يوجد في باريس العديد من الملاعب المخصصة لمختلف أنواع الرياضات. يعدّ ملعب فرنسا الذي يتسع لأكثر من 80 ألف متفرج أكبر ملاعب البلاد، وكان قد بني هذا الملعب الواقع في منطقة سان دينس لاستضافة كأس العالم لكرة القدم 1998 والذي حازت عليه فرنسا للمرة الأولى في تاريخها. يستخدم الملعب لممارسة كرة القدم، والرجبي، وألعاب القوى. يستضيف الملعب مباريات منتخب فرنسا الوطني للرجبي سنوياً في بطولة الأمم الستة. وكذلك يستضيف مباريات منتخب فرنسا لكرة القدم الودية وتصفيات البطولات الكبرى. بالإضافة إلى نادي باريس سان جيرمان، تملك المدينة نوادي كرة قدم أخرى مثل: نادي باريس، والنجم الأحمر ونادي فرنسا\"\n",
        "for i in range(0,4):\n",
        "    test_text = train_contexts[i]\n",
        "    show_encoding_of(test_text, tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xSCcsX9TrlSo"
      },
      "outputs": [],
      "source": [
        "def add_token_positions(encodings, answers):\n",
        "    # initialize lists to contain the token indices of answer start/end\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "    for i in range(len(answers)):\n",
        "        # append start/end token position using char_to_token method\n",
        "        \n",
        "        if('answer_end' not in answers[i]):\n",
        "            continue\n",
        "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
        "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']))\n",
        "        \n",
        "\n",
        "        # if start position is None, the answer passage has been truncated\n",
        "        if start_positions[-1] is None:\n",
        "            start_positions[-1] = tokenizer.model_max_length\n",
        "        # end position cannot be found, char_to_token found space, so shift one token forward\n",
        "        go_back = 1\n",
        "        # print(end_positions[-1])\n",
        "        while end_positions[-1] is None:\n",
        "            end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end']-go_back)\n",
        "            go_back +=1\n",
        "    # update our encodings object with the new token-based start/end positions\n",
        "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "\n",
        "# apply function to our data\n",
        "add_token_positions(train_encodings, train_answers)\n",
        "add_token_positions(val_encodings, val_answers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "ENHokIYyrlSp",
        "outputId": "6f4b9e63-ff9a-4d06-a0eb-854b8cff04ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['_MutableMapping__marker', '__abstractmethods__', '__class__', '__class_getitem__', '__contains__', '__copy__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__ior__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__or__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__ror__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_encodings', '_n_sequences', 'char_to_token', 'char_to_word', 'clear', 'convert_to_tensors', 'copy', 'data', 'encodings', 'fromkeys', 'get', 'is_fast', 'items', 'keys', 'n_sequences', 'pop', 'popitem', 'sequence_ids', 'setdefault', 'to', 'token_to_chars', 'token_to_sequence', 'token_to_word', 'tokens', 'update', 'values', 'word_ids', 'word_to_chars', 'word_to_tokens', 'words']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask', 'start_positions', 'end_positions'])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14316\n",
            "14316\n",
            "14316\n",
            "14316\n",
            "[CLS] ويستند اقتصاد برمودا على التأمين وإعادة التأمين والسياحة ، وهما أكبر قطاعين اقتصاديين في الجزيرة. وكانت برمودا صاحبة إحدى أعلى معدلات الناتج المحلي الإجمالي للفرد في العالم في معظم سنوات القرن العشرين ولعدة سنوات بعدها. تأثر وضعها الاقتصادي في الآونة الأخيرة بسبب الركود العالمي. مناخ الجزيرة هو شبه استوائي. وبرمودا هي أقصى نقطة في شمال مثلث برمودا ، وهي منطقة من البحر اختفت فيها عدة سفن وطائرات في ظروف غامضة كما تقول الأسطورة. تقع الجزيرة في حزام الأعاصير وهي عرضة للرياح العاتية. ومع ذلك ، فهي محمية نوعا ما من كامل القوة التدميرية للأعاصير بفضل الشعاب المرجانية المحيطة بها. [SEP] ما هي أكبر القطاعات الاقتصادية في برمودا ؟ [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
          ]
        }
      ],
      "source": [
        "print(dir(train_encodings))\n",
        "display(train_encodings.data.keys())\n",
        "print(len(train_encodings.data['input_ids']))\n",
        "print(len(train_encodings.data['attention_mask']))\n",
        "print(len(train_encodings.data['start_positions']))\n",
        "print(len(train_encodings.data['end_positions']))\n",
        "print(tokenizer.decode( train_encodings.data['input_ids'][0]))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfK103WGrlSq"
      },
      "source": [
        "# Importing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvGXCnsCrlSq",
        "outputId": "698ea0ca-c9bc-4e15-87c4-6ebd6be2022a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertForQuestionAnswering: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "class SquadDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "    def convert_idx_to_text(input_ids, idx):\n",
        "        return tokenizer.decode(input_ids[idx], skip_special_tokens=True)\n",
        "\n",
        "train_dataset = SquadDataset(train_encodings)\n",
        "val_dataset = SquadDataset(val_encodings)\n",
        "from transformers import DistilBertForQuestionAnswering\n",
        "model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-multilingual-cased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3km0uNTDinS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oyq5OdirlSr",
        "outputId": "05278d67-b747-46e3-9dea-fba43dd64b50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14316\n"
          ]
        }
      ],
      "source": [
        "print(len(train_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooeFnNqSrlSr"
      },
      "source": [
        "# Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EyY3CMuy6Ca",
        "outputId": "60024d2d-d679-4e05-f80e-ff0d6452ccf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed May 17 22:30:55 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 511.79       Driver Version: 511.79       CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
            "| N/A   68C    P0    23W /  N/A |    465MiB /  6144MiB |      7%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      3380    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A      4836    C+G   ...\\Autodesk AdSSO\\AdSSO.exe    N/A      |\n",
            "|    0   N/A  N/A      9628    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
            "|    0   N/A  N/A     11864    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
            "|    0   N/A  N/A     11960    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
            "|    0   N/A  N/A     12184    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
            "|    0   N/A  N/A     13376    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
            "|    0   N/A  N/A     13404    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
            "|    0   N/A  N/A     14900    C+G   C:\\Windows\\System32\\dwm.exe     N/A      |\n",
            "|    0   N/A  N/A     16244    C+G   ...8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
            "|    0   N/A  N/A     17812    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "memory_allocated 5098476032\n",
            "max_memory_allocated 5098476032\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# set the max_split_size_mb parameter to 1024 MB\n",
        "torch.backends.cuda.matmul.allow_tf32 = False\n",
        "torch.backends.cuda.max_split_size_mb = 1024\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "print(\"memory_allocated\",torch.cuda.memory_allocated())\n",
        "print(\"max_memory_allocated\",torch.cuda.max_memory_allocated())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrdOthGxrlSr",
        "outputId": "2314c722-5fd8-447f-d6f6-70ab99e671b4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/895 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 6.00 GiB total capacity; 4.75 GiB already allocated; 0 bytes free; 4.75 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[51], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m start_positions \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_positions\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     37\u001b[0m end_positions \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_positions\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 38\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstart_positions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_positions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m              \u001b[49m\u001b[43mend_positions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_positions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# calculate loss for every parameter that needs grad update\u001b[39;00m\n",
            "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1111\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1109\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1110\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1111\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1112\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1113\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:885\u001b[0m, in \u001b[0;36mDistilBertForQuestionAnswering.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    874\u001b[0m \u001b[39mstart_positions (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[39m    Labels for position (index) of the start of the labelled span for computing the token classification loss.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    881\u001b[0m \u001b[39m    are not taken into account for computing the loss.\u001b[39;00m\n\u001b[0;32m    882\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    883\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m--> 885\u001b[0m distilbert_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdistilbert(\n\u001b[0;32m    886\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m    887\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    888\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    889\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m    890\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    891\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    892\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    893\u001b[0m )\n\u001b[0;32m    894\u001b[0m hidden_states \u001b[39m=\u001b[39m distilbert_output[\u001b[39m0\u001b[39m]  \u001b[39m# (bs, max_query_len, dim)\u001b[39;00m\n\u001b[0;32m    896\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)  \u001b[39m# (bs, max_query_len, dim)\u001b[39;00m\n",
            "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1111\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1109\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1110\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1111\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1112\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1113\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:581\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[39m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m    579\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m--> 581\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(input_ids, inputs_embeds)  \u001b[39m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    583\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer(\n\u001b[0;32m    584\u001b[0m     x\u001b[39m=\u001b[39membeddings,\n\u001b[0;32m    585\u001b[0m     attn_mask\u001b[39m=\u001b[39mattention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    589\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[0;32m    590\u001b[0m )\n",
            "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1111\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1109\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1110\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1111\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1112\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1113\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:120\u001b[0m, in \u001b[0;36mEmbeddings.forward\u001b[1;34m(self, input_ids, input_embeds)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[39mParameters:\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[39m    input_ids (torch.Tensor):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39membeddings)\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[39mif\u001b[39;00m input_ids \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m     input_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mword_embeddings(input_ids)  \u001b[39m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[0;32m    122\u001b[0m seq_length \u001b[39m=\u001b[39m input_embeds\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m)\n\u001b[0;32m    124\u001b[0m \u001b[39m# Setting the position-ids to the registered buffer in constructor, it helps\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[39m# when tracing the model without passing position-ids, solves\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[39m# isues similar to issue #5664\u001b[39;00m\n",
            "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1111\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1109\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1110\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1111\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1112\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1113\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 158\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[0;32m    159\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[0;32m    160\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
            "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2183\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2177\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2178\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2179\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2180\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2181\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2182\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2183\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 6.00 GiB total capacity; 4.75 GiB already allocated; 0 bytes free; 4.75 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers import AdamW\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import random\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "# setup GPU/CPU\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# move model over to detected device\n",
        "model.to(device)\n",
        "# activate training mode of model\n",
        "model.train()\n",
        "# initialize adam optimizer with weight decay (reduces chance of overfitting)\n",
        "optim = AdamW(model.parameters(), lr=5e-5)\n",
        "# try increase batch size to 16 on colab \n",
        "# initialize data loader for training data\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, worker_init_fn=np.random.seed(seed))\n",
        "for epoch in range(6):\n",
        "    # set model to train mode\n",
        "    model.train()\n",
        "    # setup loop (we use tqdm for the progress bar)\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "    for batch in loop:\n",
        "        # initialize calculated gradients (from prev step)\n",
        "        optim.zero_grad()\n",
        "        # pull all the tensor batches required for training\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        start_positions = batch['start_positions'].to(device)\n",
        "        end_positions = batch['end_positions'].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask,\n",
        "                        start_positions=start_positions,\n",
        "                      end_positions=end_positions)\n",
        "        loss = outputs[0]\n",
        "        # calculate loss for every parameter that needs grad update\n",
        "        loss.backward()\n",
        "        # update parameters\n",
        "        optim.step()\n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "        # print relevant info to progress bar\n",
        "        loop.set_description(f'Epoch {epoch}')\n",
        "        loop.set_postfix(loss=loss.item(), avg_loss=total_loss / num_batches)\n",
        "        avg_epoch_loss = total_loss / num_batches\n",
        "    \n",
        "    #evaluate the model after the epoch\n",
        "    # switch model out of training mode\n",
        "    model.eval()\n",
        "    #val_sampler = SequentialSampler(val_dataset)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=2,  shuffle=True, worker_init_fn=np.random.seed(seed))\n",
        "    acc = []\n",
        "    # initialize loop for progress bar\n",
        "    loop = tqdm(val_loader, leave=True)\n",
        "    # loop through batches\n",
        "    for batch in loop:\n",
        "        # we don't need to calculate gradients as we're not training\n",
        "        with torch.no_grad():\n",
        "            # pull batched items from loader\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            start_true = batch['start_positions'].to(device)\n",
        "            end_true = batch['end_positions'].to(device)\n",
        "            # make predictions\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            # pull preds out\n",
        "            start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
        "            end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
        "            # calculate accuracy for both and append to accuracy list\n",
        "            acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n",
        "            acc.append(((end_pred == end_true).sum()/len(end_pred)).item())\n",
        "            loop.set_description(f'Epoch {epoch}')\n",
        "            loop.set_postfix(avg_acc=sum(acc)/len(acc))\n",
        "            # avg_acc = sum(acc)/len(acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHe_MG1erlSs"
      },
      "source": [
        "# Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3x_jE5RrlSs",
        "outputId": "5fc1d8af-00d9-4c19-d20b-553baabca179"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/GUC related/NLP_Project_data/models/distilbert-all13/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/GUC related/NLP_Project_data/models/distilbert-all13/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/GUC related/NLP_Project_data/models/distilbert-all13/vocab.txt',\n",
              " '/content/drive/MyDrive/GUC related/NLP_Project_data/models/distilbert-all13/added_tokens.json',\n",
              " '/content/drive/MyDrive/GUC related/NLP_Project_data/models/distilbert-all13/tokenizer.json')"
            ]
          },
          "execution_count": 194,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def getNewPathName(model_path):\n",
        "  if os.path.exists(model_path):\n",
        "    model_name = os.path.basename(model_path)  # Get the base name of the model path\n",
        "    base_path = os.path.dirname(model_path)  # Get the directory path\n",
        "\n",
        "    # Find the current number at the end of the model name (e.g., \"distilbert-all1\")\n",
        "    model_number = 1\n",
        "    while os.path.exists(model_path):\n",
        "        model_number += 1\n",
        "        model_path = os.path.join(base_path, f\"{model_name}{model_number}\")\n",
        "    return model_path\n",
        "model_path = getNewPathName('/content/drive/MyDrive/GUC related/NLP_Project_data/models/distilbert-all1')\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHGhsmMzrlSt"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFpPOT8OrlSt",
        "outputId": "341721bd-4b64-4b39-e222-9e110c0693ca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 224/224 [00:58<00:00,  3.86it/s]\n"
          ]
        }
      ],
      "source": [
        "# switch model out of training mode\n",
        "model.eval()\n",
        "\n",
        "#val_sampler = SequentialSampler(val_dataset)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16,  shuffle=True, worker_init_fn=np.random.seed(seed))\n",
        "\n",
        "acc = []\n",
        "\n",
        "# initialize loop for progress bar\n",
        "loop = tqdm(val_loader)\n",
        "# loop through batches\n",
        "for batch in loop:\n",
        "    # we don't need to calculate gradients as we're not training\n",
        "    with torch.no_grad():\n",
        "        # pull batched items from loader\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        start_true = batch['start_positions'].to(device)\n",
        "        end_true = batch['end_positions'].to(device)\n",
        "        # make predictions\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        # pull preds out\n",
        "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
        "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
        "        # calculate accuracy for both and append to accuracy list\n",
        "        acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n",
        "        acc.append(((end_pred == end_true).sum()/len(end_pred)).item())\n",
        "# calculate average accuracy in total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VSPawl1Xo0O",
        "outputId": "bc69d291-e2df-42fb-89eb-3694ee2d9b70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.25, 0.125, 0.125, 0.125, 0.125, 0.1875, 0.1875, 0.125, 0.3125, 0.375, 0.1875, 0.1875, 0.3125, 0.125, 0.25, 0.125, 0.25, 0.25, 0.3125, 0.25, 0.1875, 0.125, 0.1875, 0.3125, 0.3125, 0.375, 0.1875, 0.1875, 0.125, 0.1875, 0.1875, 0.25, 0.25, 0.3125, 0.3125, 0.375, 0.125, 0.125, 0.1875, 0.125, 0.1875, 0.1875, 0.0, 0.125, 0.1875, 0.1875, 0.125, 0.1875, 0.25, 0.5, 0.0625, 0.0625, 0.1875, 0.3125, 0.25, 0.1875, 0.0625, 0.125, 0.125, 0.1875, 0.25, 0.1875, 0.5, 0.375, 0.3125, 0.375, 0.125, 0.0625, 0.25, 0.25, 0.0625, 0.3125, 0.1875, 0.0625, 0.1875, 0.1875, 0.25, 0.25, 0.125, 0.125, 0.1875, 0.1875, 0.25, 0.375, 0.125, 0.125, 0.1875, 0.25, 0.125, 0.125, 0.3125, 0.25, 0.0625, 0.1875, 0.25, 0.375, 0.375, 0.375, 0.3125, 0.25, 0.3125, 0.3125, 0.125, 0.0, 0.0625, 0.1875, 0.125, 0.1875, 0.25, 0.1875, 0.125, 0.0625, 0.25, 0.25, 0.1875, 0.3125, 0.125, 0.125, 0.1875, 0.1875, 0.25, 0.1875, 0.1875, 0.25, 0.5625, 0.5, 0.125, 0.125, 0.375, 0.125, 0.25, 0.3125, 0.25, 0.3125, 0.25, 0.1875, 0.375, 0.4375, 0.125, 0.25, 0.25, 0.3125, 0.3125, 0.375, 0.25, 0.3125, 0.4375, 0.3125, 0.125, 0.25, 0.3125, 0.3125, 0.125, 0.125, 0.25, 0.25, 0.1875, 0.125, 0.125, 0.1875, 0.3125, 0.375, 0.125, 0.1875, 0.125, 0.125, 0.25, 0.1875, 0.0625, 0.1875, 0.0625, 0.1875, 0.25, 0.25, 0.1875, 0.1875, 0.3125, 0.25, 0.25, 0.125, 0.25, 0.125, 0.125, 0.0625, 0.375, 0.4375, 0.25, 0.25, 0.25, 0.25, 0.25, 0.375, 0.25, 0.3125, 0.25, 0.25, 0.0625, 0.125, 0.3125, 0.375, 0.1875, 0.3125, 0.3125, 0.3125, 0.1875, 0.1875, 0.0625, 0.125, 0.0625, 0.25, 0.4375, 0.5, 0.25, 0.25, 0.1875, 0.1875, 0.1875, 0.0625, 0.25, 0.25, 0.25, 0.1875, 0.125, 0.1875, 0.25, 0.1875, 0.25, 0.25, 0.125, 0.125, 0.25, 0.1875, 0.375, 0.3125, 0.25, 0.375, 0.1875, 0.3125, 0.3125, 0.375, 0.375, 0.1875, 0.1875, 0.25, 0.25, 0.1875, 0.3125, 0.3125, 0.25, 0.25, 0.25, 0.25, 0.1875, 0.1875, 0.375, 0.375, 0.1875, 0.25, 0.25, 0.25, 0.0625, 0.0625, 0.3125, 0.125, 0.3125, 0.1875, 0.0625, 0.125, 0.1875, 0.1875, 0.25, 0.3125, 0.3125, 0.375, 0.25, 0.25, 0.25, 0.3125, 0.3125, 0.3125, 0.25, 0.25, 0.125, 0.1875, 0.0625, 0.125, 0.25, 0.4375, 0.1875, 0.1875, 0.4375, 0.25, 0.3125, 0.125, 0.125, 0.25, 0.1875, 0.125, 0.25, 0.3125, 0.1875, 0.1875, 0.375, 0.5, 0.3125, 0.4375, 0.25, 0.1875, 0.1875, 0.1875, 0.0625, 0.125, 0.25, 0.25, 0.25, 0.25, 0.1875, 0.1875, 0.1875, 0.1875, 0.1875, 0.125, 0.4375, 0.625, 0.3125, 0.25, 0.1875, 0.1875, 0.1875, 0.25, 0.1875, 0.0625, 0.125, 0.1875, 0.375, 0.375, 0.1875, 0.1875, 0.0625, 0.25, 0.3125, 0.125, 0.125, 0.1875, 0.25, 0.125, 0.0625, 0.25, 0.0625, 0.0625, 0.1875, 0.125, 0.1875, 0.1875, 0.1875, 0.3125, 0.125, 0.25, 0.3125, 0.3125, 0.3125, 0.4375, 0.125, 0.125, 0.0625, 0.1875, 0.3125, 0.375, 0.0625, 0.125, 0.1875, 0.125, 0.375, 0.375, 0.1875, 0.1875, 0.0, 0.0625, 0.1875, 0.1875, 0.125, 0.3125, 0.0625, 0.0625, 0.1875, 0.1875, 0.0625, 0.25, 0.25, 0.1875, 0.3125, 0.25, 0.25, 0.125, 0.25, 0.25, 0.25, 0.1875, 0.1875, 0.1875, 0.5, 0.3125, 0.1875, 0.125, 0.1875, 0.375, 0.25, 0.3125, 0.3125, 0.3125, 0.25, 0.3125, 0.5, 0.4375, 0.1875, 0.1875, 0.1875, 0.125, 0.25, 0.1875, 0.1875, 0.25, 0.0625, 0.0625, 0.3125, 0.25, 0.125, 0.25, 0.3125, 0.125, 0.3125, 0.4375, 0.125, 0.125, 0.25, 0.3125, 0.1875, 0.3125, 0.25, 0.1875, 0.125, 0.1875, 0.0625, 0.0, 0.125, 0.125, 0.5, 0.5]\n",
            "0.22419084821428573\n"
          ]
        }
      ],
      "source": [
        "avg_acc = sum(acc)/len(acc)\n",
        "print(acc)\n",
        "print(avg_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuHAC_VPDAQC",
        "outputId": "9af2a60d-9323-4b27-de89-07843a19d412"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-197-748282866fe3>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# convert indices to strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mstart_pred_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_idx_to_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mend_pred_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_idx_to_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-197-748282866fe3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# convert indices to strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mstart_pred_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_idx_to_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mend_pred_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_idx_to_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: SquadDataset.convert_idx_to_text() takes 2 positional arguments but 3 were given"
          ]
        }
      ],
      "source": [
        "import Levenshtein\n",
        "\n",
        "# ...\n",
        "\n",
        "tolerance = 0.9  # Set your desired tolerance level between 0 and 1\n",
        "\n",
        "exact_match_count = 0\n",
        "total_count = 0\n",
        "\n",
        "# loop through batches\n",
        "for batch in loop:\n",
        "    # ...\n",
        "\n",
        "    # pull preds out\n",
        "    start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
        "    end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
        "\n",
        "    # convert indices to strings\n",
        "    start_pred_str = [val_dataset.convert_idx_to_text(input_ids[i], start_pred[i].item()) for i in range(len(start_pred))]\n",
        "    end_pred_str = [val_dataset.convert_idx_to_text(input_ids[i], end_pred[i].item()) for i in range(len(end_pred))]\n",
        "\n",
        "    start_true_str = [val_dataset.convert_idx_to_text(input_ids[i], start_true[i].item()) for i in range(len(start_true))]\n",
        "    end_true_str = [val_dataset.convert_idx_to_text(input_ids[i], end_true[i].item()) for i in range(len(end_true))]\n",
        "\n",
        "    # calculate exact match with tolerance for both start and end positions\n",
        "    for pred, true in zip(start_pred_str, start_true_str):\n",
        "        if Levenshtein.ratio(pred, true) >= tolerance:\n",
        "            exact_match_count += 1\n",
        "        total_count += 1\n",
        "\n",
        "    for pred, true in zip(end_pred_str, end_true_str):\n",
        "        if Levenshtein.ratio(pred, true) >= tolerance:\n",
        "            exact_match_count += 1\n",
        "        total_count += 1\n",
        "\n",
        "# calculate exact match with tolerance accuracy\n",
        "exact_match_tolerance_accuracy = exact_match_count / total_count if total_count != 0 else 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJhYM2mFrlSu"
      },
      "outputs": [],
      "source": [
        "print(\"T/F\\tstart\\tend\\n\")\n",
        "for i in range(len(start_true)):\n",
        "    print(f\"true\\t{start_true[i]}\\t{end_true[i]}\\n\"\n",
        "          f\"pred\\t{start_pred[i]}\\t{end_pred[i]}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEtH7EQzrlSu"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.16 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b09ec625f77bf4fd762565a912b97636504ad6ec901eb2d0f4cf5a7de23e1ee5"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0189149c653542b18af29a72f337a296": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07ca26fe07e248fa9a9954ba10410d72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08e03b0a847f4e589e2088ec8a91ec4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a43fd56b91b4cc7bfee68915b4423fd",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41d3b87964fa4dd499e7581f8c9c2081",
            "value": 112
          }
        },
        "0a43fd56b91b4cc7bfee68915b4423fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1226da27fe514e1780844c2bac6561c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14ab6f4a79d845dfb4a4dfdb3064b54c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f231d7196a054148bdbac98926e4a3cf",
            "placeholder": "​",
            "style": "IPY_MODEL_582370614edb443888dec80fe6d962a4",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "182f88c03556458f99d131a05f669428": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c71af7dbc4cf46e7bbf8262925fa5f41",
            "placeholder": "​",
            "style": "IPY_MODEL_1226da27fe514e1780844c2bac6561c6",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "1a2b73653c414700b9ad6e025cea4cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26d17baf11d341c6bec339cddc8e7e12",
            "max": 637,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc034347a3704bda8d3ff402f481441c",
            "value": 637
          }
        },
        "1d5bd38c6e8649feaf03993a9529a9d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14ab6f4a79d845dfb4a4dfdb3064b54c",
              "IPY_MODEL_08e03b0a847f4e589e2088ec8a91ec4b",
              "IPY_MODEL_67a364467c69448da3a615cbff44eaaa"
            ],
            "layout": "IPY_MODEL_37310c5ad6e840c5ba16ccb9c17a4f4c"
          }
        },
        "25437c4fb55341bd8fb13beef8118421": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26d17baf11d341c6bec339cddc8e7e12": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "280d3dfdaf204a43a556bc1d2f33228e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "283ad12349a04b6098c3b7fb0ff059f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6945f0db30ed4efeaaf197e78a2a6495",
            "placeholder": "​",
            "style": "IPY_MODEL_5bee9ea299c640fd86f525b474249e3c",
            "value": " 637/637 [00:00&lt;00:00, 42.6kB/s]"
          }
        },
        "2f5a3096a800456b97e2a1f52425d061": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f831e284d854b8db5fda93454f11cf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "329a2ab616874c7284d84a89e5e901df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59d661c98ada4778a3ce9efe729b3997",
            "placeholder": "​",
            "style": "IPY_MODEL_6c474507d57d459595685c6034e23454",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "37310c5ad6e840c5ba16ccb9c17a4f4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c1a0e5bbdb44208a288638b05ca6cd6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41d3b87964fa4dd499e7581f8c9c2081": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "471069fec4594096916f8b9d7e4c6ef7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "582370614edb443888dec80fe6d962a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59d661c98ada4778a3ce9efe729b3997": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bee9ea299c640fd86f525b474249e3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63efd25c6410466d976aad803f53f897": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66405b5df8ab44bfa498ff080dd530f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_280d3dfdaf204a43a556bc1d2f33228e",
            "placeholder": "​",
            "style": "IPY_MODEL_b320aadc6edf47448e8900b3ebd95d28",
            "value": " 2.26M/2.26M [00:00&lt;00:00, 5.57MB/s]"
          }
        },
        "67a364467c69448da3a615cbff44eaaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_471069fec4594096916f8b9d7e4c6ef7",
            "placeholder": "​",
            "style": "IPY_MODEL_2f5a3096a800456b97e2a1f52425d061",
            "value": " 112/112 [00:00&lt;00:00, 3.25kB/s]"
          }
        },
        "6945f0db30ed4efeaaf197e78a2a6495": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b250c6ab34d4f5db09bfd2d42c8626c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c474507d57d459595685c6034e23454": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7007b5312eb14f6b950a41b9cf8ef35d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71fd70e4960149628eef41f9b61def34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79650a9b9d7e43eb8317b77915f0a1c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0189149c653542b18af29a72f337a296",
            "max": 578,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71fd70e4960149628eef41f9b61def34",
            "value": 578
          }
        },
        "7acfa42bf35149948c7ff8215ff92529": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7eae82df839b4f49882c25b6f8196be2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63efd25c6410466d976aad803f53f897",
            "max": 717153,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f831e284d854b8db5fda93454f11cf2",
            "value": 717153
          }
        },
        "80225c74ac2949fdbad4a79952859944": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "877c929bcb544615823588a2331e777a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_182f88c03556458f99d131a05f669428",
              "IPY_MODEL_1a2b73653c414700b9ad6e025cea4cec",
              "IPY_MODEL_283ad12349a04b6098c3b7fb0ff059f9"
            ],
            "layout": "IPY_MODEL_7007b5312eb14f6b950a41b9cf8ef35d"
          }
        },
        "95c6781289b64a3db1dd364d11c616e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3073fe7da3f42daa0186f881eafff5a",
              "IPY_MODEL_79650a9b9d7e43eb8317b77915f0a1c6",
              "IPY_MODEL_adc9eb70f17648bbb564e2d933d3874e"
            ],
            "layout": "IPY_MODEL_6b250c6ab34d4f5db09bfd2d42c8626c"
          }
        },
        "967c3bbd01794ed29a1006c86a5de7ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e68b4ce93474acfb0cab00a1457aa00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab9aa109770045e3a156dc87053de4a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adc9eb70f17648bbb564e2d933d3874e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c1a0e5bbdb44208a288638b05ca6cd6",
            "placeholder": "​",
            "style": "IPY_MODEL_ab9aa109770045e3a156dc87053de4a0",
            "value": " 578/578 [00:00&lt;00:00, 25.8kB/s]"
          }
        },
        "b320aadc6edf47448e8900b3ebd95d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b794a7ed5cfa48869cc66c9558bd81c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f23d1f1e11ec401993ee26489b00370d",
            "max": 2259454,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07ca26fe07e248fa9a9954ba10410d72",
            "value": 2259454
          }
        },
        "c3073fe7da3f42daa0186f881eafff5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9141616ee6e418997257e31d0575d3a",
            "placeholder": "​",
            "style": "IPY_MODEL_9e68b4ce93474acfb0cab00a1457aa00",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "c71af7dbc4cf46e7bbf8262925fa5f41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c89f28bd39764446a743291ac0ee79c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d75ef1d79de34adab125acab8b9207fc",
            "placeholder": "​",
            "style": "IPY_MODEL_cbf5eb602e08443ea0484d828337900f",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "cbf5eb602e08443ea0484d828337900f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d75ef1d79de34adab125acab8b9207fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9141616ee6e418997257e31d0575d3a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc034347a3704bda8d3ff402f481441c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6323fc8cbbc416286dbadd69d95baad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c89f28bd39764446a743291ac0ee79c5",
              "IPY_MODEL_7eae82df839b4f49882c25b6f8196be2",
              "IPY_MODEL_e795b00ba6bb4734b3ebd3bfa27e6d3b"
            ],
            "layout": "IPY_MODEL_7acfa42bf35149948c7ff8215ff92529"
          }
        },
        "e795b00ba6bb4734b3ebd3bfa27e6d3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80225c74ac2949fdbad4a79952859944",
            "placeholder": "​",
            "style": "IPY_MODEL_967c3bbd01794ed29a1006c86a5de7ee",
            "value": " 717k/717k [00:00&lt;00:00, 8.73MB/s]"
          }
        },
        "eb7b6ccb53d147fe90486f23571c73a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_329a2ab616874c7284d84a89e5e901df",
              "IPY_MODEL_b794a7ed5cfa48869cc66c9558bd81c0",
              "IPY_MODEL_66405b5df8ab44bfa498ff080dd530f4"
            ],
            "layout": "IPY_MODEL_25437c4fb55341bd8fb13beef8118421"
          }
        },
        "f231d7196a054148bdbac98926e4a3cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f23d1f1e11ec401993ee26489b00370d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
