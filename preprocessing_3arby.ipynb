{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "بيونسيه\n",
      "\n",
      "[{'qas': [{'question': 'متى بدأت بيونسي تصبح شعبية؟', 'id': 1, 'answers': [{'text': 'في أواخر التسعينات', 'answer_start': 220}], 'is_impossible': False}, {'question': 'ما هي المجالات التي تنافس عليها بيونسيه عندما كانت تكبر؟', 'id': 2, 'answers': [{'text': 'غناء ورقص', 'answer_start': 173}], 'is_impossible': False}, {'question': 'متى غادرت بيونسي طفل القدر وتصبح مغنية منفردة؟', 'id': 3, 'answers': [{'text': '(2003)،', 'answer_start': 515}], 'is_impossible': False}, {'question': 'في أي مدينة و ولاية نشأت بيونسيه؟', 'id': 4, 'answers': [{'text': 'هيوستن بولاية تكساس،', 'answer_start': 88}], 'is_impossible': False}, {'question': 'في أي عقد أصبحت بيونسي مشهورة؟', 'id': 5, 'answers': [{'text': 'أواخر التسعينات', 'answer_start': 223}], 'is_impossible': False}, {'question': 'في أي مجموعة R&B كانت هي المغنية الرئيسية؟', 'id': 6, 'answers': [{'text': 'دستنيز تشايلد', 'answer_start': 290}], 'is_impossible': False}, {'question': 'ما الألبوم الذي جعلها فنانة معروفة عالميا؟', 'id': 7, 'answers': [{'text': 'Dangerously in Love', 'answer_start': 476}], 'is_impossible': False}, {'question': 'من أدار مجموعة مصير الطفل؟', 'id': 8, 'answers': [{'text': 'ماثيو نولز،', 'answer_start': 332}], 'is_impossible': False}, {'question': 'متى صعدت بيونسي إلى الشهرة؟', 'id': 9, 'answers': [{'text': 'أواخر التسعينات', 'answer_start': 223}], 'is_impossible': False}, {'question': 'ما الدور الذي لعبه بيونسيه في طفل القدر؟', 'id': 10, 'answers': [{'text': 'فنان منفرد ناجح', 'answer_start': 545}], 'is_impossible': False}, {'question': 'ما هو أول ألبوم صدر بيونسيه كفنان منفرد؟', 'id': 11, 'answers': [{'text': 'Dangerously in Love', 'answer_start': 476}], 'is_impossible': False}, {'question': 'متى أطلقت بيونسيه خطير في الحب؟', 'id': 12, 'answers': [{'text': '(2003)،', 'answer_start': 515}], 'is_impossible': False}, {'question': 'كم عدد جوائز Grammy التي فازت بها Beyoncé لأول ألبوم منفرد لها؟', 'id': 13, 'answers': [{'text': 'خمسة', 'answer_start': 604}], 'is_impossible': False}, {'question': 'ماذا كان دور بيونسيه في طفل القدر؟', 'id': 14, 'answers': [{'text': 'فنان منفرد ناجح', 'answer_start': 545}], 'is_impossible': False}, {'question': 'ما هو اسم أول ألبوم منفرد لبيونسي؟', 'id': 15, 'answers': [{'text': 'Dangerously in Love', 'answer_start': 476}], 'is_impossible': False}], 'context': 'بيونسي جيزيل نولز-كارتر (من مواليد 4 سبتمبر، 1981)، المعروفة باسم بيونسي. ولدت ونشأت في هيوستن بولاية تكساس، هي مغنية وممثلة أميركية حائزة على 23 جائزة غرامي.غنت في مسابقات غناء ورقص مختلفة عندما كانت طفلة، أصبحت مشهورة في أواخر التسعينات كمغنية آر أند بي (رئيسية) للفرقة الغنائية النسائية دستنيز تشايلد. والتي أديرت من قِبل والدها ماثيو نولز، وأصبحت الفرقة واحدة من الأكثر مبيعاً في العالم من الفرق النسائية على الإطلاق. وقد شهد إنفصال الفرقة المؤقت صدور ألبوم بيونسي الأول  Dangerously in Love دانجيروسلي إن لوف  (2003)، والذي أنشأها بأن تكون فنان منفرد ناجح في العالم؛ بيعت منه 16 مليون نسخة، حصل على خمسة جوائز غرامي وتضمن الأغاني التي وصلت إلى قمة الرسم البياني الأمريكي بيلبورد هوت 100 \"كريزي إن لوف\" و\"بيبي بوي\". \\n'}, {'qas': [{'question': 'في أي مدينة ذهبت بيونسي إلى المدرسة؟', 'id': 16, 'answers': [{'text': 'فريدريكسبورغ', 'answer_start': 63}], 'is_impossible': False}, {'question': 'من كان أول شخص يلاحظ قدرة بيونسي على الغناء؟', 'id': 17, 'answers': [{'text': 'دارلاتا جونسون', 'answer_start': 128}], 'is_impossible': False}, {'question': 'انتقلت بيونسي إلى أي مدينة بعد أن تركت مدرستها الابتدائية الأولى؟', 'id': 18, 'answers': [{'text': 'هيوستن،', 'answer_start': 849}], 'is_impossible': False}, {'question': 'أي من أساتذتها اكتشفوا موهبة بيونسي الموسيقية؟', 'id': 19, 'answers': [{'text': 'جونسون مدرس الرقص لبيونسي', 'answer_start': 136}], 'is_impossible': False}, {'question': 'أنا الكنيسة التي كانت بيونسيه عضو وعازف منفرد في الجوقة؟', 'id': 20, 'answers': [{'text': 'القديس', 'answer_start': 43}], 'is_impossible': False}, {'question': 'ما نوع المدرسة التي كانت مدرسة باركر الابتدائية؟', 'id': 21, 'answers': [{'text': 'مدرسة أليف السيك،', 'answer_start': 882}], 'is_impossible': False}, {'question': 'ما الأغنية التي غنتها بيونسي للفوز في مسابقة في سن السابعة؟', 'id': 22, 'answers': [{'text': 'من', 'answer_start': 334}], 'is_impossible': False}, {'question': 'في أي مدينة تقع مدرسة بيونسي الابتدائية؟', 'id': 23, 'answers': [{'text': 'فريدريكسبورغ', 'answer_start': 63}], 'is_impossible': False}, {'question': 'ما اسم أول مدرب للرقص في بيونسيه؟', 'id': 24, 'answers': [{'text': 'دارلاتا جونسون', 'answer_start': 128}], 'is_impossible': False}, {'question': 'ما الجوقة التي غنتها بيونسي لمدة عامين؟', 'id': 25, 'answers': [{'text': 'القديس', 'answer_start': 43}], 'is_impossible': False}], 'context': \"حصلت بيونسي على تعليمها الإبتدائي في مدرسة القديس ماري التي في فريدريكسبورغ (تكساس). وحصلت هناك أيضاً على دروس الرقص. وقد اكتشف دارلاتا جونسون مدرس الرقص لبيونسي موهبتها الغنائية عندما بدأت في همهمة تلحين أغنية بصوتها (إحدى الأغنيات)، وقد ضغط عليها حتى تكمل الأغنية. وقد فازت بيونسي في مسابقة للغناء وأداء الصوت عندما كانت في السابعة من عمرها، وباقي المشتركين في الخامسة عشر، والسادسة عشر. وقد قامت بغناء أغنية تخيل للمغن والشاعر وعازف جيتار فرقة البيتلز جون لينون. وهي أغنية تصف عالمًا مثاليًا تتحقق فيه المساواة والسلام بين بني البشر. الأغنية من كلمات جون لينون ومن إخراج فيل سبيكتور. وقد صدرت لأول مرة عام-1971 كجزء من ألبوم إيماجين. وتعد الأغنية واحدة من أفضل الأغاني وأكثرها شيوعًا، وفي عام 2004 حلت في المرتبة الثالثة على قائمة رولينغ ستون لأفضل خمسمائة أغنية في التاريخ. وفي خريف عام 1990، وتنضم بيونسي إلى مدرسة باركر الابتدائية للموسيقى في هيوستن، تكساس. وبعد ذلك ذهبت إلى مدرسة أليف السيك، الثانوية للفنون المسرحية والفنون البصرية. بالإضافة إلى قضائها سنتين كاملتين في مدرسة الكنيسة الميثودية المتحدة St. John's.\\n\"}, {'qas': [{'question': 'من قرر وضع مجموعة بيونسيه في برنامج Star Search في عرض المواهب؟', 'id': 26, 'answers': [{'text': 'آرنى فراجير', 'answer_start': 299}], 'is_impossible': False}, {'question': 'من كان أول علامة سجل لإعطاء الفتيات صفقة قياسية؟', 'id': 27, 'answers': [{'text': 'مع إلكترا', 'answer_start': 829}], 'is_impossible': False}, {'question': 'من الذي أحضر بيونسي إلى كاليفورنيا ودخل مجموعتها في Star Search؟', 'id': 28, 'answers': [{'text': 'آرنى فراجير', 'answer_start': 299}], 'is_impossible': False}, {'question': 'في أي عام ترك والد بيونسي وظيفته لإدارة مجموعتها؟', 'id': 29, 'answers': [{'text': '1995', 'answer_start': 527}], 'is_impossible': False}, {'question': 'ما هي شركة التسجيلات الكبيرة التي سجلت أول ألبوم لمجموعة بيونسيه؟', 'id': 30, 'answers': [{'text': 'سوني للموسيقى', 'answer_start': 1173}], 'is_impossible': False}, {'question': 'ما شركة تسجيل وقعت لأول مرة مجموعة بيونسي وقطعت في وقت لاحق لهم؟', 'id': 31, 'answers': [{'text': 'مع إلكترا', 'answer_start': 829}], 'is_impossible': False}, {'question': 'من وضع Tyme الفتاة في البحث عن النجوم؟', 'id': 32, 'answers': [{'text': 'آرنى فراجير', 'answer_start': 299}], 'is_impossible': False}, {'question': 'من وقع على مجموعة الفتاة في 5 أكتوبر 1995؟', 'id': 33, 'answers': [{'text': 'للتسجيلات في', 'answer_start': 839}], 'is_impossible': False}], 'context': 'وتقابلت بيونسي وصديقة طفولتها كيلي رولاند مع لا تفيا روبرسون في انتخابات مجموعات التسلية والترفيه التي تكونت من تجمع فتيات في عمر الثمانية. وقاموا بإنشاء مجموعة مع ثلاث فتيات آخريات وأسسوها بعنوان فتاة التيمي وقاموا بالرقص وغناء الراب في نطاق مسابقة المواهب في هيوستن. وبعد الإطلاع على المجموعة قام آرنى فراجير منتج R&B بإحضار الفتيات إلى الإستوديو في شمال كاليفورنيا، وفي ذلك الوقت شاركوا في مسابقة (البحث عن نجم) أكبر مسابقة مواهب عُرضت على شاشة التلفاز. وقامت بيونسي بأداء أغنية في مسابقة فتاة التيمي ولكنها لم تفز. وفي عام 1995 غادر والد بيونسي إدارة المجموعة. ونتيجة لذلك فقد حدّ دخل عائلة بيونسي واضطر كل من والدها ووالدتها الانتقال إلى شقق منفصلة. وانخفض مستوى مجموعة ماثيو المبتكر إلى الترتيب الرابع واستمرت هذه المجموعة في الظهور على المسرح وحتى من قبل ظهور مجموعة الفتيات R&B المعروفين. وقامت هذه المجموعة بعقد إتفاقية مع إلكترا للتسجيلات في عام 1995 وبعد وقت لاحق من هذه الإتفاقية تم إنهاؤها من قبل الشركة، وأدى هذا الحدث إلى زيادة التوتر في العائلة وانفصل والديّ بيونسي. وفي الخامس من شهر أكتوبر عام 1995 قامت الشعبية الترفيهية صاحبة دويني ويغينز بعقد إتفاقية مع الفتيات. وفي عام 1996 بدأت المجموعة بتسجيل ألبومها الأول في إطار الإتفاقية والذي قام بإنتاجه شركة سوني للموسيقى. وتوحدت أسرة نولز من جديد وبعد فترة ما وقعت الفتيات إتفاقية جديدة مع كولومبيا للتسجيلات.\\n'}, {'qas': [{'question': '\"الملائكة تشارلي\" ظهرت أي واحد من أعضاء الفرقة؟', 'id': 34, 'answers': [{'text': 'بيعت منه أكثر', 'answer_start': 1007}], 'is_impossible': False}, {'question': 'باع ألبومهم الثالث ، Survivor ، كم خلال أسبوعه الأول؟', 'id': 35, 'answers': [{'text': 'نسخة', 'answer_start': 1032}], 'is_impossible': False}, {'question': 'ما هو الملحن الفرنسي الذي كتب الأوبرا الأصلية \"كارمن\" في القرن التاسع عشر؟', 'id': 36, 'answers': [{'text': 'جيمس', 'answer_start': 367}], 'is_impossible': False}, {'question': 'النساء المستقلات الجزء الأول كان على 2000 فيلم موسيقى؟', 'id': 37, 'answers': [{'text': 'ساشا فيرس', 'answer_start': 438}], 'is_impossible': False}, {'question': 'ما الفيلم الذي نجحت بيونسي في إنتاجه عام 2001 مع Mekhi Phifer؟', 'id': 38, 'answers': [{'text': 'من قِبل', 'answer_start': 976}], 'is_impossible': False}, {'question': 'متى أعلن مصير الطفل عن توقفه؟', 'id': 39, 'answers': [{'text': 'فيرس (2008)،', 'answer_start': 443}], 'is_impossible': False}], 'context': 'بعد انفصال دستنيز تشايلد في 2005، أصدرت ألبومها الإستديو الثاني المنفرد بي دي (2006)، والذي تضمن الأغاني التي نجحت عالمياً \"أيربليسبل\" و\"بيوتفل لاير\". بيونسي معروفة في التمثيل أيضاً، مع أدائها الذي ترشح لجائزة جولدن جلوب في دريم قيرلز (2006). وأدوار بطولة أخرى في ذا بينك بانتر (2006) وأوبسيسد (2009). وتزوجت من مغني الراب جي-زي وتجسيدها للشخصية المغنية الراحلة إيتا جيمس في كاديلاك ريكوردز (2008) أثر على ألبومها الإستديو الثالث، آيم... ساشا فيرس (2008)، والذي شهد ولادة الشخصية البديلة ساشا فيرس وحصل الألبوم على ستة جوائز غرامي في 2010، بما في ذلك أغنية السنة لأغنية \"سنقل ليديز (بوت آ رينق أون إت)\". أخذت بيونسي إجازة من عالم الفن في عام 2010 وتولت إدارة حياتها المهنية، أصدرت ألبومها الإستديو الرابع 4 (2011) الذي كان يحتوي على نبرة ناضجة أكثر من ألبوماتها السابقة، واستكشفت موسيقى الفانك الذي كان في السبعينات مع هذا الألبوم، والبوب في الثمنينات والسول التسعينات، كما أن ألبوم \\'4\\' تسرب بشكل كامل قبل صدوره بشكل رسمي مما يجعل الألبوم أكثر ألبوم تم تحميله بشكل غير قانوني من قِبل فنانة أنثى، رغم تسريبه بيعت منه أكثر من 8 مليون نسخة عالمياً  ألبومها الإستديو الخامس، بيونسي (2013)، تلقى الألبوم على الكثير من المراجعات الإيجابية من نقاد الموسيقى وفضلوه على ألبوماتها السابقة بسبب نوع الألبوم المظلم، كما أن الألبوم تم صدوره بشكل مفاجئ وبيعت منه 828,773 نسخة عالمياً في أول ثلاث أيام من صدوره من دون أي ترويج مسبق.\\n'}, {'qas': [{'question': 'كم عدد نسخ ألبوماتها التي باعتها بيونسي في الولايات المتحدة؟', 'id': 40, 'answers': [{'text': 'مليون', 'answer_start': 221}], 'is_impossible': False}, {'question': 'إجمالي في جميع أنحاء العالم ، كم عدد السجلات التي بيعت بيونسيها؟', 'id': 41, 'answers': [{'text': 'مليون', 'answer_start': 221}], 'is_impossible': False}, {'question': 'عندما كانت بيونسيه مع Destiny Child ، كم عدد الألبومات التي تمكنت من بيعها؟', 'id': 42, 'answers': [{'text': 'و60 مليون', 'answer_start': 275}], 'is_impossible': False}, {'question': 'من كانت أول امرأة تحصل على جائزة الفنان العالمي في جوائز الموسيقى الأمريكية؟', 'id': 43, 'answers': [{'text': 'بيونسي', 'answer_start': 400}], 'is_impossible': False}, {'question': 'كم عدد الألبومات التي بيعت بيونسي كفنان منفرد في الولايات المتحدة؟', 'id': 44, 'answers': [{'text': 'مليون', 'answer_start': 221}], 'is_impossible': False}, {'question': 'كم باعت في جميع أنحاء العالم؟', 'id': 45, 'answers': [{'text': 'مليون', 'answer_start': 221}], 'is_impossible': False}, {'question': \"كم عدد السجلات التي باعتها مع Destiny's Child؟\", 'id': 46, 'answers': [{'text': 'و60 مليون', 'answer_start': 275}], 'is_impossible': False}, {'question': 'متى حصلت على جائزة الأسطورة؟', 'id': 47, 'answers': [{'text': 'جوائز موسيقى', 'answer_start': 103}], 'is_impossible': False}, {'question': 'كم عدد السجلات التي باعتها بيونسيه في الولايات المتحدة؟', 'id': 48, 'answers': [{'text': 'أكثر من 200 مليون', 'answer_start': 209}], 'is_impossible': False}, {'question': 'كم عدد السجلات التي باعها بيونسيه في جميع أنحاء العالم؟', 'id': 49, 'answers': [{'text': 'أكثر من 200 مليون', 'answer_start': 209}], 'is_impossible': False}, {'question': 'متى حصلت بيونسيه على جائزة الأسطورة؟', 'id': 50, 'answers': [{'text': 'جوائز موسيقى', 'answer_start': 103}], 'is_impossible': False}], 'context': 'وحصلت على 23 جائزة غرامي وهي المرأة الأكثر ترشيحًا في تاريخ الجائزة، وهي أيضًا الفنانة الأكثر حصدًا في جوائز موسيقى فيديو MTV ، مع 24 فوزًا ،  وأكثر من 600 جائزة طوال حياتها المهنية التي امتدت 16 عاماً، وباعت أكثر من 200 مليون نسخة من الألبومات والأغاني المنفردة كفنان منفرد و60 مليون مع دستنيز تشايلد، مما يجعلها واحدة من أفضل الفنانين مبيعاً على الإطلاق. أعترفت جمعية صناعة التسجيلات الأمريكية بأن بيونسي أعلى فنان معتمد في أمريكا خلال العقد 2000s. في 2009، سميت بيلبورد بيونسي أعلى فنان راديو لهذا العقد، أعلى فنانة من عقد 2000s وفنان الألفية من قبل بيلبورد في عام 2011. في 2014، أدرجت تايم بيونسي واحدة من أكثر 100 شخصية مؤثرة في العالم.\\n'}]\n"
     ]
    }
   ],
   "source": [
    "with open('AQAD-master/AQQAD 1.0/FINAL_AAQAD-v1.0.json','rb') as f:\n",
    "  data = json.load(f)\n",
    "\n",
    "for allData in data['data']:\n",
    "    print(allData['title']+\"\\n\")\n",
    "    print(allData['paragraphs'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        squad_dict = json.load(f)\n",
    "\n",
    "    # initialize lists for contexts, questions, and answers\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    # iterate through all data in squad data\n",
    "    for group in squad_dict['data']:\n",
    "        for passage in group['paragraphs']:\n",
    "            context = passage['context']\n",
    "            for qa in passage['qas']:\n",
    "                question = qa['question']\n",
    "                if 'plausible_answers' in qa.keys():\n",
    "                    access = 'plausible_answers'\n",
    "                else:\n",
    "                    access = 'answers'\n",
    "                for answer in qa['answers']:\n",
    "                    # append data to lists\n",
    "                    contexts.append(context)\n",
    "                    questions.append(question)\n",
    "                    answers.append(answer)\n",
    "    # return formatted data lists\n",
    "    return contexts, questions, answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts, questions, answers = read_data('AQAD-master/AQQAD 1.0/FINAL_AAQAD-v1.0.json')\n",
    "#splitting the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_contexts, val_contexts, train_questions, val_questions, train_answers, val_answers = train_test_split(contexts, questions, answers, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ما الذي تم بناء استاد فرنسا من أجله؟',\n",
       " 'كيف ألقاب الجماعة درع لديه أرسنال؟',\n",
       " 'في أي اتجاه يُنشر الخشب في كثير من الأحيان بحيث تظهر عقدة كدائرة صلبة تتدفق الحبوب حولها؟']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'text': 'كأس العالم لكرة القدم', 'answer_start': 187},\n",
       " {'text': '2014،', 'answer_start': 919},\n",
       " {'text': 'الألواح بطول 366 سم وبعرض', 'answer_start': 9}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['يوجد في باريس العديد من الملاعب المخصصة لمختلف أنواع الرياضات. يعدّ ملعب فرنسا الذي يتسع لأكثر من 80 ألف متفرج أكبر ملاعب البلاد، وكان قد بني هذا الملعب الواقع في منطقة سان دينس لاستضافة كأس العالم لكرة القدم 1998 والذي حازت عليه فرنسا للمرة الأولى في تاريخها. يستخدم الملعب لممارسة كرة القدم، والرجبي، وألعاب القوى. يستضيف الملعب مباريات منتخب فرنسا الوطني للرجبي سنوياً في بطولة الأمم الستة. وكذلك يستضيف مباريات منتخب فرنسا لكرة القدم الودية وتصفيات البطولات الكبرى. بالإضافة إلى نادي باريس سان جيرمان، تملك المدينة نوادي كرة قدم أخرى مثل: نادي باريس، والنجم الأحمر ونادي فرنسا.\\n',\n",
       " 'شهد عام 2006 نجاحا للأرسنال على المستوى الأوروبي حيث تأهل للمرة الأولى في تاريخيه إلى المباراة النهائية لدوري أبطال أوروبا التي أقيمت في العاصمة الفرنسية باريس وجمعت الأرسنال مع نادي برشلونة الإسباني وكان الأرسنال قريبا من تحقيق لقبه الأوروبي الأول بعد أن أنهى الشوط الأول بتقدمه بهدف سجله مدافعه الإنجليزي سول كامبل. لكن أحلامهم في الحصول على اللقب تبددت بعد أن تمكن النادي الإسباني من قلب النتيجة لصالحه بتسجيله هدفين في الربع الأخير من المباراة ليتوج بذلك بطل لأوروبا على حساب الآرسنال. وفي يوليو 2006، انتقل النادي إلى ملعبه الجديد ملعب الإمارات بعد 93 سنة في قضاها في معلب الهايبري. وصل أرسنال إلى نهائي كأس الرابطة الإنجليزية للمحترفين في موسم 2010–11، وخسر بنتيجة 2-1 لصالح برمنغهام سيتي، وأصبح منذ بداية شهر مارس من عام 2011، أحد الأندية الأربعة (الثلاثة الأخرى هي: مانشستر يونايتد، بلاكبيرن روفرز، وتشيلسي) التي فازت بكأس بطولة الدوري الإنجليزي، منذ تأسيسها عام 1992. لم يظفر أرسنال بأي بطولة مهمة حتى 17 مايو 2014، عندما هزم نادي هال سيتي في نهائي كأس الاتحاد الإنجليزي لكرة القدم بنتيجة 3–2 بعد أن كان متراجعاً في بداية المباراة بنتيجة 2–0، فتأهل نتيجة لذلك إلى بطولة درع الاتحاد الإنجليزي لسنة 2014، حيث نافس بطل الدوري الممتاز مانشستر سيتي، وفاز عليه بنتيجة 3–0 ليحرز بطولة ثانية خلال ثلاثة أشهر فقط. وبعد حوالي تسعة شهور من الفوز بدرع الاتحاد الإنجليزي، عاود أرسنال الظهور في بطولة كأس الاتحاد الإنجليزي للسنة الثانية على التوالي، ليهوم نادي أستون فيلا في النهائي بنتيجة 4–0 ويُصبح بالتالي أنجح النوادي في تاريخ هذه اليطولة، بعد أن ظفر بها 12 مرة خلال تاريخه. وبتاريخ 2 أغسطس 2015 هزم أرسنال نادي تشيلسي بنتيجة 1–0 في ملعب ومبرلي ليحتفظ بلقبه كبطل درع الاتحاد، للمرة الرابعة عشر.\\n',\n",
       " 'تنتج هذه الألواح بطول 366 سم وبعرض 122 سم عادة وإن كانت بعض المصانع الأجنبية تنتج ألواحاً بطول 500 سم أيضاً. ويختلف الخشب المضغوط عن الخشب الحبيبي في أن صناعة الأول تتم بعد تحويل الألياف السليلوزية إلى عجينة شبيهة بعجينة الورق ثم تخلط بالراتنج (الصمغ)، ويتم تشكيل الألواح بالضغط العالي عند درجات حرارة مرتفعة كما هو الحال في الخشب الحبيبي، إلا أن الألواح الخشبية تعالج بعد ذلك في أفران للتحميص حتى لا تتأثر مستقبلاً بتغييرات درجات الحرارة أو الرطوبة الموجودة في الجو.\\n']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_questions[0:3])\n",
    "display(train_answers[0:3])\n",
    "display(train_contexts[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ما هي البكتيريا التي تسبب عدوى السل؟',\n",
       " 'ما هي البكتيريا التي تسبب مرض الحمى التي رصدت في جبال روكي؟',\n",
       " 'كم من السكان الأصليين بالقرب من ولاية ماساتشوستس لقوا حتفهم بسبب الجدري في الوباء بين عامي 1617 و 1619؟']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'text': 'السل', 'answer_start': 89},\n",
       " {'text': 'أنواع', 'answer_start': 706},\n",
       " {'text': '30% من الأمريكيين الأصليين القاطنين في', 'answer_start': 512}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['من المُقدّر أن حوالي 5 - 10٪ من غير المُصابين بفيروس نقص المناعة البشرية والمصابين بعدوى السل سيصبح مرضهم نشطًا خلال حياتهم وفي المقابل، فإن 30٪ من المُصابين بفيروس نقص المناعة البشرية سيصبح مرضهم نشطًا. قد يُصيب السل أي جزء من الجسم، ولكن إصابته للرئتين تُعتبر الأكثر شيوعًا (وهو ما يُعرف باسم السل الرئوي). يحدث السل خارج الرئوي عندما يتطور مرض السل خارج الرئتين. قد يتشارك السل خارج الرئوي مع السل الرئوي أيضًا  تشمل العلامات والأعراض العامة الحمى والقشعريرة والتعرق الليلي وفقدان الشهية وفقدان الوزن والتعب،  وقد يحدث تعجّر الأصابع الواضح أيضًا.\\n',\n",
       " 'يمتلك كل نوع من الأمراض مميزات خاصة به تمكنه من التفاعل مع مستقبلاته في الجسم البشري. فبعض الكائنات الحية مثل المكورات العقدية يمكن أن تسبب الالتهابات الجلدية، والالتهاب الرئوي، والسحايا، وتسمم الدم حيث ينتج صدمة فتتوسع وتتضخم الأوعية مما يسبب الموت. مع ذلك فإن هذه الكائنات الحية هي أيضا جزء من الإنسان، وعادةً ما تتواجد على الجلد أو في الأنف من دون أن تسبب أي مرض على الإطلاق. وهناك كائنات أخرى دائماً تسبب الأمراض لدى البشر مثل الريكتسية وهي من الطفيليات، حيث تتواجد وتنمو وتتكاثر داخل خلايا الكائنات الحية الأخرى. كما أن هناك نوع واحد من الريكتسية يسبب التيفوس، في حين يسبب البعض حمى جبال روكي المبقعة. بالإضافة إلى أن هناك شعبة الكلاميديا وهي من الطفيليات التي تنمو وتتكاثر داخل الخلايا حيث تحتوي على أنواع من الممكن أن تسبب الالتهاب الرئوي، والتهاب المسالك ويمكن أن تشارك في أمراض القلب التاجية.] وأخيرا، بعض الأنواع مثل الزائفة الزنجارية وبيركولديري، والمتفطرة الطيرية من مسببات الأمراض الانتهازية وتسبب المرض بشكل خاص لدى الأشخاص الذين يعانون من ضعف المناعة والتليف الكيسي.\\n',\n",
       " 'يقدر أن الاجتياح المتكرر بالإنفلونزا والحصبة والجدري أدى في تناقص ما قدر بنصف إلى ثلثي السكان الأصليين لشرق أمريكا الشمالية في ظرف قرن من الغزو الأوروبي للمنطقة، وقد قدر أن الجدري تسبب في فناء 90% من السكان الأصليين لمستعمرة خليج ماساتشوستس، كما تسبب انتقال فيروس الجدري من الأوروبيين إلى الأمريكيين الأصليين في بلايموث (بولاية ماساتشوستس الحالية) في انقراضهم جميعاً. وقد وصل المرض إلى منطقة بحيرة أونتاريو سنة 1836 وإلى أراضي الإيروكواس بحلول عام 1679. وفي سبعينيات القرن الثامن عشر قضى الجدري على ما لا يقل عن 30% من الأمريكيين الأصليين القاطنين في الساحل الغربي للولايات المتحدة، كما تسببت أوبئة الجدري التي حلت في الفترة بين عامي 1780 و1782 وفي الفترة بين عامي 1837 و1838 في تناقص شديد في أعداد هنود منطقة السهول. وكانت حكومة الولايات المتحدة الأمريكية قد نظمت برنامجاً لتطعيم الأمريكيين الأصليين ضد الجدري سنة 1832 (قانون تطعيم الهنود لسنة 1832).\\n']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(val_questions[0:3])\n",
    "display(val_answers[0:3])\n",
    "display(val_contexts[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_end_idx(answers, contexts):\n",
    "    # loop through each answer-context pair\n",
    "    for answer, context in zip(answers, contexts):\n",
    "        # gold_text refers to the answer we are expecting to find in context\n",
    "        gold_text = answer['text']\n",
    "        # we already know the start index\n",
    "        start_idx = answer['answer_start']\n",
    "        # and ideally this would be the end index...\n",
    "        end_idx = start_idx + len(gold_text)\n",
    "\n",
    "        # ...however, sometimes squad answers are off by a character or two\n",
    "        if context[start_idx:end_idx] == gold_text:\n",
    "            # if the answer is not off :)\n",
    "            answer['answer_end'] = end_idx\n",
    "        else:\n",
    "            for n in [1, 2]:\n",
    "                if context[start_idx-n:end_idx-n] == gold_text:\n",
    "                    # this means the answer is off by 'n' tokens\n",
    "                    answer['answer_start'] = start_idx - n\n",
    "                    answer['answer_end'] = end_idx - n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_end_idx(train_answers, train_contexts)\n",
    "add_end_idx(val_answers, val_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'answers without answer_end key:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'non matching answers:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'answers without answer_end key:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'non matching answers:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loop over train answers and train contexts and make sure that they match\n",
    "def check_answers_contexts_match(answers, contexts, questions, show_anamolies=False):\n",
    "    \n",
    "    answers_without_answer_end_key =0\n",
    "    non_matching_answers=0\n",
    "    for answer, context, question in zip(answers, contexts, questions):\n",
    "        \n",
    "        #check if context has key answer_end and if not \n",
    "        if 'answer_end' not in answer.keys():\n",
    "            answers_without_answer_end_key +=1\n",
    "            if show_anamolies:\n",
    "                print(question)\n",
    "                print(answer)\n",
    "                print(context[answer['answer_start']:answer['answer_start']+ len(answer['text'])+1])\n",
    "            continue \n",
    "\n",
    "        #check if answer matches context\n",
    "        if context[answer['answer_start']:answer['answer_end']] != answer['text']:\n",
    "            non_matching_answers +=1\n",
    "    display('answers without answer_end key:', answers_without_answer_end_key,'non matching answers:', non_matching_answers)\n",
    "    \n",
    "check_answers_contexts_match(train_answers, train_contexts, train_questions)\n",
    "check_answers_contexts_match(val_answers, val_contexts, val_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "disilbert_tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: arabert in d:\\anaconda3\\lib\\site-packages (1.0.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: emoji==1.4.2 in d:\\anaconda3\\lib\\site-packages (from arabert) (1.4.2)\n",
      "Requirement already satisfied: farasapy in d:\\anaconda3\\lib\\site-packages (from arabert) (0.0.14)\n",
      "Requirement already satisfied: PyArabic in d:\\anaconda3\\lib\\site-packages (from arabert) (0.6.15)\n",
      "Requirement already satisfied: requests in d:\\anaconda3\\lib\\site-packages (from farasapy->arabert) (2.28.1)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda3\\lib\\site-packages (from farasapy->arabert) (4.64.1)\n",
      "Requirement already satisfied: six>=1.14.0 in d:\\anaconda3\\lib\\site-packages (from PyArabic->arabert) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests->farasapy->arabert) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests->farasapy->arabert) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests->farasapy->arabert) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\anaconda3\\lib\\site-packages (from requests->farasapy->arabert) (2.0.4)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\lib\\site-packages (from tqdm->farasapy->arabert) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "%pip install arabert\n",
    "from transformers import AutoTokenizer\n",
    "# from arabert.preprocess_arabert import never_split_tokens, preprocess\n",
    "arabert_tokenizer = AutoTokenizer.from_pretrained(\"aubmindlab/bert-base-arabert\", do_lower_case=False, do_basic_tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_encoding_of(sentence, tokenizer):\n",
    "    encoding = tokenizer(sentence)\n",
    "    print(sentence)\n",
    "    print(encoding)\n",
    "    print('length of encoding:', len(encoding['input_ids']))\n",
    "    for i in encoding['input_ids']:\n",
    "        #print the decoding of it\n",
    "        print(i,':',tokenizer.decode([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "الألواح الخشبية تعالج بعد ذلك في أفران للتحميص حتى لا تتأثر مستقبلاً بتغييرات درجات الحرارة أو الرطوبة الموجودة في الجو\n",
      "{'input_ids': [29756, 445, 27375, 7800, 445, 27960, 1007, 980, 33864, 3161, 4312, 781, 30353, 113, 1001, 27671, 8259, 3842, 818, 32967, 29759, 91, 53212, 7797, 4179, 7797, 445, 7874, 7804, 980, 402, 445, 988, 28626, 980, 445, 54052, 980, 781, 445, 7866, 29758], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "length of encoding: 42\n",
      "29756 : [CLS]\n",
      "445 : ال\n",
      "27375 : ##ألو\n",
      "7800 : ##اح\n",
      "445 : ال\n",
      "27960 : ##خشب\n",
      "1007 : ##ي\n",
      "980 : ##ة\n",
      "33864 : تعالج\n",
      "3161 : بعد\n",
      "4312 : ذلك\n",
      "781 : في\n",
      "30353 : أفران\n",
      "113 : ل\n",
      "1001 : ##ل\n",
      "27671 : ##تحم\n",
      "8259 : ##يص\n",
      "3842 : حتى\n",
      "818 : لا\n",
      "32967 : تتأثر\n",
      "29759 : [UNK]\n",
      "91 : ب\n",
      "53212 : ##تغيير\n",
      "7797 : ##ات\n",
      "4179 : درج\n",
      "7797 : ##ات\n",
      "445 : ال\n",
      "7874 : ##حر\n",
      "7804 : ##ار\n",
      "980 : ##ة\n",
      "402 : أو\n",
      "445 : ال\n",
      "988 : ##ر\n",
      "28626 : ##طوب\n",
      "980 : ##ة\n",
      "445 : ال\n",
      "54052 : ##موجود\n",
      "980 : ##ة\n",
      "781 : في\n",
      "445 : ال\n",
      "7866 : ##جو\n",
      "29758 : [SEP]\n"
     ]
    }
   ],
   "source": [
    "test_text = \"الألواح الخشبية تعالج بعد ذلك في أفران للتحميص حتى لا تتأثر مستقبلاً بتغييرات درجات الحرارة أو الرطوبة الموجودة في الجو\"\n",
    "show_encoding_of(test_text, arabert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "الألواح الخشبية تعالج بعد ذلك في أفران للتحميص حتى لا تتأثر مستقبلاً بتغييرات درجات الحرارة أو الرطوبة الموجودة في الجو\n",
      "{'input_ids': [101, 1270, 23673, 25573, 23673, 29836, 25573, 29820, 1270, 23673, 29821, 29825, 29816, 14498, 19433, 1273, 29830, 25573, 23673, 29819, 1271, 29830, 15394, 1279, 23673, 29835, 1291, 14498, 1270, 29833, 17149, 18511, 1294, 23673, 29817, 29820, 22192, 14498, 29826, 1276, 29817, 29837, 1294, 25573, 1273, 29817, 25573, 29818, 17149, 1295, 29824, 29817, 29834, 29816, 23673, 25573, 1271, 29817, 29831, 14498, 14498, 17149, 25573, 29817, 1278, 17149, 29819, 25573, 29817, 1270, 23673, 29820, 17149, 25573, 17149, 19433, 1270, 29836, 1270, 23673, 17149, 29828, 29836, 29816, 19433, 1270, 23673, 22192, 29836, 29819, 29836, 15394, 19433, 1291, 14498, 1270, 23673, 29819, 29836, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "length of encoding: 100\n",
      "101 : [CLS]\n",
      "1270 : ا\n",
      "23673 : ##ل\n",
      "25573 : ##ا\n",
      "23673 : ##ل\n",
      "29836 : ##و\n",
      "25573 : ##ا\n",
      "29820 : ##ح\n",
      "1270 : ا\n",
      "23673 : ##ل\n",
      "29821 : ##خ\n",
      "29825 : ##ش\n",
      "29816 : ##ب\n",
      "14498 : ##ي\n",
      "19433 : ##ة\n",
      "1273 : ت\n",
      "29830 : ##ع\n",
      "25573 : ##ا\n",
      "23673 : ##ل\n",
      "29819 : ##ج\n",
      "1271 : ب\n",
      "29830 : ##ع\n",
      "15394 : ##د\n",
      "1279 : ذ\n",
      "23673 : ##ل\n",
      "29835 : ##ك\n",
      "1291 : ف\n",
      "14498 : ##ي\n",
      "1270 : ا\n",
      "29833 : ##ف\n",
      "17149 : ##ر\n",
      "18511 : ##ان\n",
      "1294 : ل\n",
      "23673 : ##ل\n",
      "29817 : ##ت\n",
      "29820 : ##ح\n",
      "22192 : ##م\n",
      "14498 : ##ي\n",
      "29826 : ##ص\n",
      "1276 : ح\n",
      "29817 : ##ت\n",
      "29837 : ##ى\n",
      "1294 : ل\n",
      "25573 : ##ا\n",
      "1273 : ت\n",
      "29817 : ##ت\n",
      "25573 : ##ا\n",
      "29818 : ##ث\n",
      "17149 : ##ر\n",
      "1295 : م\n",
      "29824 : ##س\n",
      "29817 : ##ت\n",
      "29834 : ##ق\n",
      "29816 : ##ب\n",
      "23673 : ##ل\n",
      "25573 : ##ا\n",
      "1271 : ب\n",
      "29817 : ##ت\n",
      "29831 : ##غ\n",
      "14498 : ##ي\n",
      "14498 : ##ي\n",
      "17149 : ##ر\n",
      "25573 : ##ا\n",
      "29817 : ##ت\n",
      "1278 : د\n",
      "17149 : ##ر\n",
      "29819 : ##ج\n",
      "25573 : ##ا\n",
      "29817 : ##ت\n",
      "1270 : ا\n",
      "23673 : ##ل\n",
      "29820 : ##ح\n",
      "17149 : ##ر\n",
      "25573 : ##ا\n",
      "17149 : ##ر\n",
      "19433 : ##ة\n",
      "1270 : ا\n",
      "29836 : ##و\n",
      "1270 : ا\n",
      "23673 : ##ل\n",
      "17149 : ##ر\n",
      "29828 : ##ط\n",
      "29836 : ##و\n",
      "29816 : ##ب\n",
      "19433 : ##ة\n",
      "1270 : ا\n",
      "23673 : ##ل\n",
      "22192 : ##م\n",
      "29836 : ##و\n",
      "29819 : ##ج\n",
      "29836 : ##و\n",
      "15394 : ##د\n",
      "19433 : ##ة\n",
      "1291 : ف\n",
      "14498 : ##ي\n",
      "1270 : ا\n",
      "23673 : ##ل\n",
      "29819 : ##ج\n",
      "29836 : ##و\n",
      "102 : [SEP]\n"
     ]
    }
   ],
   "source": [
    "show_encoding_of(test_text, disilbert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = arabert_tokenizer\n",
    "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_token_positions(encodings, answers):\n",
    "    # initialize lists to contain the token indices of answer start/end\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i in range(len(answers)):\n",
    "        # append start/end token position using char_to_token method\n",
    "        \n",
    "        # old\n",
    "        # start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
    "        # end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']))\n",
    "        # Mine mah, lol I am sure it must work\n",
    "        start_positions.append(encodings.char_to_token(i, answers[i].get('answer_start', None)))\n",
    "        end_positions.append(encodings.char_to_token(i, answers[i].get('answer_end', None)))\n",
    "\n",
    "        # if start position is None, the answer passage has been truncated\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length\n",
    "        # end position cannot be found, char_to_token found space, so shift one token forward\n",
    "        go_back = 1\n",
    "        print(end_positions[-1])\n",
    "        while end_positions[-1] is None:\n",
    "            # old\n",
    "            # end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end']-go_back)\n",
    "            end_positions[-1] = encodings.char_to_token(i, answers[i].get('answer_end', i)-go_back)\n",
    "            go_back +=1\n",
    "    # update our encodings object with the new token-based start/end positions\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "\n",
    "# apply function to our data\n",
    "add_token_positions(train_encodings, train_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[58,\n",
       " 310,\n",
       " 3,\n",
       " 150,\n",
       " 5,\n",
       " 24,\n",
       " 94,\n",
       " 4,\n",
       " 93,\n",
       " 16,\n",
       " 78,\n",
       " 83,\n",
       " 66,\n",
       " 71,\n",
       " 143,\n",
       " 108,\n",
       " 110,\n",
       " 85,\n",
       " 22,\n",
       " 31,\n",
       " 14,\n",
       " 167,\n",
       " 74,\n",
       " 388,\n",
       " 5,\n",
       " 39,\n",
       " 1,\n",
       " 56,\n",
       " 34,\n",
       " 115,\n",
       " 272,\n",
       " 2,\n",
       " 107,\n",
       " 4,\n",
       " 99,\n",
       " 61,\n",
       " 117,\n",
       " 19,\n",
       " 13,\n",
       " 204,\n",
       " 52,\n",
       " 143,\n",
       " 30,\n",
       " 101,\n",
       " 70,\n",
       " 5,\n",
       " 45,\n",
       " 70,\n",
       " 1,\n",
       " 197,\n",
       " 8,\n",
       " 49,\n",
       " 2,\n",
       " 18,\n",
       " 246,\n",
       " 18,\n",
       " 93,\n",
       " 74,\n",
       " 129,\n",
       " 54,\n",
       " 67,\n",
       " 26,\n",
       " 117,\n",
       " 141,\n",
       " 35,\n",
       " 82,\n",
       " 6,\n",
       " 92,\n",
       " 8,\n",
       " 133,\n",
       " 11,\n",
       " 24,\n",
       " 16,\n",
       " 352,\n",
       " 39,\n",
       " 17,\n",
       " 120,\n",
       " 32,\n",
       " 15,\n",
       " 149,\n",
       " 145,\n",
       " 253,\n",
       " 13,\n",
       " 77,\n",
       " 31,\n",
       " 21,\n",
       " 28,\n",
       " 212,\n",
       " 72,\n",
       " 66,\n",
       " 68,\n",
       " 200,\n",
       " 6,\n",
       " 225,\n",
       " 7,\n",
       " 153,\n",
       " 137,\n",
       " 128,\n",
       " 58,\n",
       " 144]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings['start_positions'][0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b09ec625f77bf4fd762565a912b97636504ad6ec901eb2d0f4cf5a7de23e1ee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
